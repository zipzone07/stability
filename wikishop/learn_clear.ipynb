{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6211f24-66b8-4069-89aa-178fbced6def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 00:32:52.898329: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759692772.933957   11971 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759692772.985406   11971 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759692773.261928   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759692773.261953   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759692773.261956   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759692773.261958   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import pandas as pd # –∞–Ω–∞–ª–∏–∑ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "import numpy as np # –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è –º–æ—â —è–∑—ã–∫–∞ –°\n",
    "import matplotlib.pyplot as plt # –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "import seaborn as sns # —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "#from datetime import datetime # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç –∏ –≤—Ä–µ–º–µ–Ω–∏\n",
    "#import re # —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è\n",
    "from collections import Counter # —Å–ª–æ–≤–∞—Ä—å-–ø–æ–¥–∫–ª–∞—Å—Å –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ö—ç—à –¥–∞–Ω–Ω—ã—Ö\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # –î–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "from sklearn.model_selection import ( # —Ä–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    KFold\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score, \n",
    "    classification_report,\n",
    "    make_scorer\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer # –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "from sklearn.linear_model import LogisticRegression # –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å\n",
    "from sklearn.neural_network import MLPClassifier # \n",
    "from sklearn.multioutput import MultiOutputClassifier # –º—É–ª—å—Ç–∏-–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "import joblib # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "import warnings # –∫–æ–Ω—Ç—Ä–æ–ª—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π\n",
    "warnings.filterwarnings('ignore') # –ø–æ–¥–∞–≤–∏—Ç—å –≤—Å–µ –Ω–µ –∫—Ä–∏—Ç. –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "import spacy\n",
    "import nltk  # –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "from nltk.corpus import stopwords  # —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "from tqdm import tqdm  # –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä—ã\n",
    "import pickle\n",
    "\n",
    "# –°–∫–∞—á–∏–≤–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')  # –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')  # —Å–∫–∞—á–∏–≤–∞–µ–º –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4364e28b-3a74-4718-a217-b59949150180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —ç—Ç–∞–ø–∞ 1\n",
    "with open('processed_data.pkl', 'rb') as f:  # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è —á—Ç–µ–Ω–∏—è\n",
    "    data = pickle.load(f)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "\n",
    "# –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è\n",
    "calls_auto = data['calls_auto']  # –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∞–≤—Ç–æ—Ä–∞–∑–º–µ—Ç–∫–∞)\n",
    "calls_manual = data['calls_manual']  # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ä—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞)\n",
    "y_auto = data['y_auto']  # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ\n",
    "y_manual = data['y_manual']  # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ\n",
    "tags_list = data['tags_list']  # –°–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ –∑–∞–∫–∞–∑—á–∏–∫–∞\n",
    "all_tags = data['all_tags'] # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–µ–≥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "employees_list = data['employees_list']  # –°–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤\n",
    "competitors_list = ['competitors_list'] # —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤\n",
    "brands_list = data['brands_list']  # –°–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥–æ–≤\n",
    "materials_list = data['materials_list']  # –°–ø–∏—Å–æ–∫ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n",
    "mlb_classes = data['mlb_classes']\n",
    "available_in_train = data['available_in_train']  # –¢–µ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤ —Ç—Ä–µ–π–Ω–µ\n",
    "available_in_test = data['available_in_test']  # –¢–µ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤ —Ç–µ—Å—Ç–µ\n",
    "not_available_in_train = data['not_available_in_train'] # –¢–µ–≥–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ —Ç—Ä–µ–π–Ω–µ\n",
    "not_available_in_test = data['not_available_in_test'] # –¢–µ–≥–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ —Ç–µ—Å—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed026ed6-9ec3-4e2b-ad16-d8e345358bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: 1900 —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤\n",
      "–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: 127 —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤\n",
      "–í—Å–µ–≥–æ —Ç–µ–≥–æ–≤: 38\n",
      "–¢–µ–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: 27\n",
      "–ò–Ω–¥–µ–∫—Å—ã —Ç–µ–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: [30, 36, 6, 17, 12, 31, 24, 0, 37, 2, 19, 22, 10, 34, 29, 33, 11, 4, 13, 16, 15, 27, 28, 26, 23, 8, 35]\n"
     ]
    }
   ],
   "source": [
    "print(f'–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(calls_auto)} —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤')  # –†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "print(f'–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(calls_manual)} —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤')  # –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "print(f'–í—Å–µ–≥–æ —Ç–µ–≥–æ–≤: {len(all_tags)}')  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤\n",
    "print(f'–¢–µ–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {len(available_in_test)}')  # –¢–µ–≥–∏ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –≤ —Ç–µ—Å—Ç–µ\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫–∏ –¥–ª—è —Ç–µ–≥–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "available_indices = [list(all_tags).index(tag) for tag in available_in_test]  # –ò–Ω–¥–µ–∫—Å—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ–≥–æ–≤\n",
    "available_tags_names = [list(all_tags)[i] for i in available_indices]  # –ù–∞–∑–≤–∞–Ω–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ–≥–æ–≤\n",
    "print(f'–ò–Ω–¥–µ–∫—Å—ã —Ç–µ–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {available_indices}')  # –í—ã–≤–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3511eedd-2f23-4df0-9e95-5b50f2390ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 156 —Å—Ç–æ–ø-—Å–ª–æ–≤\n"
     ]
    }
   ],
   "source": [
    "# –ë–∞–∑–æ–≤—ã–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏–∑ NLTK\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω—è–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏\n",
    "phone_stopwords = {'–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ', '–¥–æ–±—Ä—ã–π', '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', '—Å–ø–∞—Å–∏–±–æ', '–∞–ª–ª–æ'}\n",
    "russian_stopwords.update(phone_stopwords)\n",
    "\n",
    "print(f'–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(russian_stopwords)} —Å—Ç–æ–ø-—Å–ª–æ–≤')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68f80aa-7340-496f-840d-8fd03450cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç–æ–ø-—Å–ª–æ–≤ –≤ —Å–ø–∏—Å–æ–∫\n",
    "russian_stopwords = list(russian_stopwords)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,           # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á\n",
    "    min_df=5,                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞\n",
    "    max_df=0.8,                 # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞  \n",
    "    stop_words=russian_stopwords, # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "    ngram_range=(1, 3),          # –£–Ω–∏–≥—Ä–∞–º–º—ã –∏ —Ç—Ä–∏–≥—Ä–∞–º–º—ã\n",
    "    lowercase=True,              # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    use_idf=True,                # –ò—Å–ø–æ–ª—å–∑—É–µ–º IDF –≤–µ—Å–∞\n",
    "    sublinear_tf=True            # –°—É–±–ª–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ TF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558b58f1-1894-48d5-8627-6b13a46d445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—É—á–µ–Ω–∏–µ TF-IDF...\n",
      "–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å train: (1900, 5000)\n",
      "–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å test: (127, 5000)\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á: 5000\n"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–∞–µ–º TF-IDF –Ω–∞ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö\n",
    "print('–û–±—É—á–µ–Ω–∏–µ TF-IDF...')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(calls_auto['lemmatized_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(calls_manual['lemmatized_text'])\n",
    "\n",
    "print(f'–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å train: {X_train_tfidf.shape}')\n",
    "print(f'–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å test: {X_test_tfidf.shape}')\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ —Ñ–∏—á\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á: {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88dd975-f659-4019-8b7d-552e59b7db54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3de18a-d8ad-403d-9c99-7e7072d01a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['–ë—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è', '–í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞', '–î–æ–ª–≥–æ–ø—Ä—É–¥–Ω—ã–π —Å–∫–ª–∞–¥', '–î–æ—Å—Ç–∞–≤–∫–∞',\n",
       "       '–ñ–∞–ª–æ–±—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É', '–ó–∞–∫—Ä—ã–≤–∞—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã', '–ó–∞—Å—Ç–∞–≤—Å–∫–∞—è –æ—Ñ–∏—Å',\n",
       "       '–ö–∞—Ä–º–∞—Ç–µ—Ö/–∫–∞—Ä–º–∞–ø–ª–∞—Å—Ç', '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã', '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –±—Ä–µ–Ω–¥—É',\n",
       "       '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª—É', '–ù–µ —Ç–æ—Ä–≥—É–µ—Ç—Å—è', '–ù–µ—Ç —Ç–æ–≤–∞—Ä–∞/—É—Å–ª—É–≥–∏',\n",
       "       '–ù–µ—Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä', '–ù–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ',\n",
       "       '–û–∑–æ–Ω/–í–±/–∏–Ω—ã–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã', '–û–ø–ª–∞—Ç–∞', '–û—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è',\n",
       "       '–û—Ç—Å—Ä–æ—á–∫–∞', '–û—Ñ–∏—Å', '–ü–µ–Ω–∏', '–ü—Ä–µ—Ç–µ–Ω–∑–∏—è', '–ü—Ä–æ—Å—Ä–æ—á–∫–∏',\n",
       "       '–†–∞–∑–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–∞', '–†–µ–≥–∏–æ–Ω', '–†–æ—Å—Ç–æ–≤ —Å–∫–ª–∞–¥', '–°–∞–π—Ç',\n",
       "       '–°–∞–π—Ç vink.ru', '–°–∞–º–æ–≤—ã–≤–æ–∑', '–°—É–¥–µ–±–Ω–∞—è –ø—Ä–µ—Ç–µ–Ω–∑–∏—è', '–¢–æ—Ä–≥—É–µ—Ç—Å—è',\n",
       "       '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è', '–§–∞–º–∏–ª–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤', '–ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã',\n",
       "       '–®–æ—É—Ä—É–º –ï–ª–∏–Ω–æ', '–®—É—à–∞—Ä—ã —Å–∫–ª–∞–¥', '–≠–î–û', '–≠–∫—Å–ø—Ä–µ—Å—Å - –¥–æ—Å—Ç–∞–≤–∫–∞'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f9dd7a-76ca-4224-9719-79b055f4301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
      "  –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: 868 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –®—É—à–∞—Ä—ã —Å–∫–ª–∞–¥: 178 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –°–∞–π—Ç vink.ru: 105 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –†–µ–≥–∏–æ–Ω: 538 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û–∑–æ–Ω/–í–±/–∏–Ω—ã–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã: 119 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è: 10 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –≠–î–û: 0 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞: 3 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –°—É–¥–µ–±–Ω–∞—è –ø—Ä–µ—Ç–µ–Ω–∑–∏—è: 34 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ü—Ä–µ—Ç–µ–Ω–∑–∏—è: 755 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª—É: 599 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ù–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ: 2 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û–ø–ª–∞—Ç–∞: 208 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ù–µ—Ç —Ç–æ–≤–∞—Ä–∞/—É—Å–ª—É–≥–∏: 45 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –°–∞–π—Ç: 188 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –±—Ä–µ–Ω–¥—É: 30 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ù–µ—Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä: 1899 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ë—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è: 1 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –†–∞–∑–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–∞: 15 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ñ–∞–ª–æ–±—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É: 4 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ö–∞—Ä–º–∞—Ç–µ—Ö/–∫–∞—Ä–º–∞–ø–ª–∞—Å—Ç: 21 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ü–µ–Ω–∏: 10 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ó–∞—Å—Ç–∞–≤—Å–∫–∞—è –æ—Ñ–∏—Å: 7 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –®–æ—É—Ä—É–º –ï–ª–∏–Ω–æ: 24 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã: 143 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –§–∞–º–∏–ª–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: 18 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: 320 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –î–æ—Å—Ç–∞–≤–∫–∞: 0 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û—Ç—Å—Ä–æ—á–∫–∞: 63 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –°–∞–º–æ–≤—ã–≤–æ–∑: 205 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –î–æ–ª–≥–æ–ø—Ä—É–¥–Ω—ã–π —Å–∫–ª–∞–¥: 186 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ü—Ä–æ—Å—Ä–æ—á–∫–∏: 772 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –†–æ—Å—Ç–æ–≤ —Å–∫–ª–∞–¥: 81 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –¢–æ—Ä–≥—É–µ—Ç—Å—è: 32 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –≠–∫—Å–ø—Ä–µ—Å—Å - –¥–æ—Å—Ç–∞–≤–∫–∞: 2 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è: 54 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û—Ñ–∏—Å: 4 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ù–µ —Ç–æ—Ä–≥—É–µ—Ç—Å—è: 25 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "–ò–∑ 38 —Ç–µ–≥–æ–≤ 34 –ø—Ä–∏–≥–æ–¥–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
      "–ë—É–¥–µ–º –æ–±—É—á–∞—Ç—å –Ω–∞ 34 —Ç–µ–≥–∞—Ö\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤\n",
    "print('–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:')\n",
    "tag_counts = y_auto.sum(axis=0)\n",
    "valid_tags_indices = []\n",
    "\n",
    "for i, (tag, count) in enumerate(zip(list(all_tags), tag_counts)):\n",
    "    print(f'  {tag}: {count} –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
    "    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏ —Å —Ö–æ—Ç—è –±—ã 2 –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "    if count > 1 and count < len(y_auto) - 1:\n",
    "        valid_tags_indices.append(i)\n",
    "\n",
    "print(f'–ò–∑ {len(list(all_tags))} —Ç–µ–≥–æ–≤ {len(valid_tags_indices)} –ø—Ä–∏–≥–æ–¥–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "y_manual_valid = y_manual[:, valid_tags_indices]\n",
    "tags_list_valid = [list(all_tags)[i] for i in valid_tags_indices]\n",
    "\n",
    "print(f'–ë—É–¥–µ–º –æ–±—É—á–∞—Ç—å –Ω–∞ {len(tags_list_valid)} —Ç–µ–≥–∞—Ö')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c36cc-886d-4962-8d3d-27b5bb9824a4",
   "metadata": {},
   "source": [
    "# –í–∞–ª–∏–¥–Ω—ã–µ —Ç–µ–≥–∏ - –º–æ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f786e-2b0d-4c93-8ed8-ff594ba5d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ä–∞–±–æ—á–∏–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "# 1. –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–æ–≤ (—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤)\n",
    "valid_tags_indices = []\n",
    "for i in range(y_auto.shape[1]):\n",
    "    if y_auto[:, i].sum() >= 5:  # –∏–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä >= 5\n",
    "        valid_tags_indices.append(i)\n",
    "\n",
    "print(f\"–í–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(valid_tags_indices)}\")\n",
    "\n",
    "# 2. –§–∏–ª—å—Ç—Ä—É–µ–º –û–ë–ê –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –æ–¥–Ω–∏–º –∏ —Ç–µ–º –∂–µ –∏–Ω–¥–µ–∫—Å–∞–º\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "y_manual_valid = y_manual[:, valid_tags_indices]\n",
    "\n",
    "# 3. –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–æ–≤\n",
    "valid_tags = [mlb_classes[i] for i in valid_tags_indices]\n",
    "print(\"–í–∞–ª–∏–¥–Ω—ã–µ —Ç–µ–≥–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:\", valid_tags)\n",
    "\n",
    "# 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "print(f\"y_auto_valid shape: {y_auto_valid.shape}\")\n",
    "print(f\"y_manual_valid shape: {y_manual_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bce9928-6c17-4546-8a59-adb747793aa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–µ—Ç—Ä–∏–∫–∞ F1-macro –Ω–∞ —Ç–µ—Å—Ç–µ - 0.25\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "base_classifier = LogisticRegression(\n",
    "    C=15,               # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    solver='lbfgs',     # –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "    max_iter=1000,      # –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "    random_state=RANDOM_STATE,    # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    verbose=0,           # –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# –ú—É–ª—å—Ç–∏-–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "multi_label_model = MultiOutputClassifier(base_classifier, n_jobs=-1)\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "\n",
    "y_pred_baseline = multi_label_model.predict(X_test_tfidf)\n",
    "baseline_score = fbeta_score(y_manual_valid, y_pred_baseline, beta=0.5, zero_division=0, average='samples')\n",
    "\n",
    "print(f'–ú–µ—Ç—Ä–∏–∫–∞ F1-macro –Ω–∞ —Ç–µ—Å—Ç–µ - {baseline_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ce73a-ab0d-4fef-9de8-2a253ba5653c",
   "metadata": {},
   "source": [
    "# –° —É—á–µ—Ç–æ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb5b65d-9b27-4f39-8ae0-9cf27e7abfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–≥–∏ —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤:\n",
      "  –ó–∞—Å—Ç–∞–≤—Å–∫–∞—è –æ—Ñ–∏—Å: 0 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –°–∞–π—Ç vink.ru: 0 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û—Å–æ–±—ã–µ —É—Å–ª–æ–≤–∏—è: 1 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ù–µ —Ç–æ—Ä–≥—É–µ—Ç—Å—è: 2 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –®–æ—É—Ä—É–º –ï–ª–∏–Ω–æ: 2 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –ö–∞—Ä–º–∞—Ç–µ—Ö/–∫–∞—Ä–º–∞–ø–ª–∞—Å—Ç: 3 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –û—Ñ–∏—Å: 4 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "  –≠–î–û: 4 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "\n",
      "–í—Å–µ–≥–æ —Ç–µ–≥–æ–≤: 38\n",
      "–í–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–æ–≤ (>=5 –ø—Ä–∏–º–µ—Ä–æ–≤): 30\n",
      "\n",
      "–¢–µ–≥–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: ['–ë—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è', '–í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞', '–î–æ–ª–≥–æ–ø—Ä—É–¥–Ω—ã–π —Å–∫–ª–∞–¥', '–î–æ—Å—Ç–∞–≤–∫–∞', '–ñ–∞–ª–æ–±—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É', '–ó–∞–∫—Ä—ã–≤–∞—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã', '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã', '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –±—Ä–µ–Ω–¥—É', '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª—É', '–ù–µ—Ç —Ç–æ–≤–∞—Ä–∞/—É—Å–ª—É–≥–∏', '–ù–µ—Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä', '–ù–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ', '–û–∑–æ–Ω/–í–±/–∏–Ω—ã–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã', '–û–ø–ª–∞—Ç–∞', '–û—Ç—Å—Ä–æ—á–∫–∞', '–ü–µ–Ω–∏', '–ü—Ä–µ—Ç–µ–Ω–∑–∏—è', '–ü—Ä–æ—Å—Ä–æ—á–∫–∏', '–†–∞–∑–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–∞', '–†–µ–≥–∏–æ–Ω', '–†–æ—Å—Ç–æ–≤ —Å–∫–ª–∞–¥', '–°–∞–π—Ç', '–°–∞–º–æ–≤—ã–≤–æ–∑', '–°—É–¥–µ–±–Ω–∞—è –ø—Ä–µ—Ç–µ–Ω–∑–∏—è', '–¢–æ—Ä–≥—É–µ—Ç—Å—è', '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è', '–§–∞–º–∏–ª–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤', '–ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã', '–®—É—à–∞—Ä—ã —Å–∫–ª–∞–¥', '–≠–∫—Å–ø—Ä–µ—Å—Å - –¥–æ—Å—Ç–∞–≤–∫–∞']\n",
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
      "  –ë—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è: 18 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞: 3 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –î–æ–ª–≥–æ–ø—Ä—É–¥–Ω—ã–π —Å–∫–ª–∞–¥: 5 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –î–æ—Å—Ç–∞–≤–∫–∞: 59 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ñ–∞–ª–æ–±—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É: 10 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: 8 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –±—Ä–µ–Ω–¥—É: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª—É: 30 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ù–µ—Ç —Ç–æ–≤–∞—Ä–∞/—É—Å–ª—É–≥–∏: 7 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ù–µ—Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä: 27 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ù–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –û–∑–æ–Ω/–í–±/–∏–Ω—ã–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã: 1 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –û–ø–ª–∞—Ç–∞: 30 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –û—Ç—Å—Ä–æ—á–∫–∞: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ü–µ–Ω–∏: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ü—Ä–µ—Ç–µ–Ω–∑–∏—è: 19 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ü—Ä–æ—Å—Ä–æ—á–∫–∏: 1 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –†–∞–∑–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–∞: 1 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –†–µ–≥–∏–æ–Ω: 13 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –†–æ—Å—Ç–æ–≤ —Å–∫–ª–∞–¥: 2 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –°–∞–π—Ç: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –°–∞–º–æ–≤—ã–≤–æ–∑: 4 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –°—É–¥–µ–±–Ω–∞—è –ø—Ä–µ—Ç–µ–Ω–∑–∏—è: 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –¢–æ—Ä–≥—É–µ—Ç—Å—è: 2 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è: 42 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –§–∞–º–∏–ª–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: 5 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã: 4 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –®—É—à–∞—Ä—ã —Å–∫–ª–∞–¥: 4 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n",
      "  –≠–∫—Å–ø—Ä–µ—Å—Å - –¥–æ—Å—Ç–∞–≤–∫–∞: 3 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\n"
     ]
    }
   ],
   "source": [
    "# –ò–∑ –≤–∞—à–µ–≥–æ –≤—ã–≤–æ–¥–∞ –≤–∏–¥–Ω–æ, —á—Ç–æ –µ—Å—Ç—å —Ç–µ–≥–∏ —Å 0 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "# –ù—É–∂–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å\n",
    "\n",
    "# 1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–≥–æ–≤ —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "tags_with_few_samples = []\n",
    "valid_tags_indices = []\n",
    "\n",
    "for i, tag_name in enumerate(mlb_classes):\n",
    "    count = y_auto[:, i].sum()\n",
    "    if count >= 5:  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        valid_tags_indices.append(i)\n",
    "    else:\n",
    "        tags_with_few_samples.append((tag_name, count))\n",
    "\n",
    "print(\"–¢–µ–≥–∏ —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤:\")\n",
    "for tag, count in sorted(tags_with_few_samples, key=lambda x: x[1]):\n",
    "    print(f\"  {tag}: {count} –ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "\n",
    "print(f\"\\n–í—Å–µ–≥–æ —Ç–µ–≥–æ–≤: {y_auto.shape[1]}\")\n",
    "print(f\"–í–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–æ–≤ (>=5 –ø—Ä–∏–º–µ—Ä–æ–≤): {len(valid_tags_indices)}\")\n",
    "\n",
    "# 2. –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "y_manual_valid = y_manual[:, valid_tags_indices]\n",
    "\n",
    "# 3. –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–æ–≤\n",
    "valid_tags = [mlb_classes[i] for i in valid_tags_indices]\n",
    "print(\"\\n–¢–µ–≥–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:\", valid_tags)\n",
    "\n",
    "# 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "for i, tag_name in enumerate(valid_tags):\n",
    "    # –ù–∞—Ö–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ç–µ–≥–∞\n",
    "    original_idx = list(mlb_classes).index(tag_name)\n",
    "    test_count = y_manual[:, original_idx].sum()\n",
    "    print(f\"  {tag_name}: {test_count} –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ç–µ—Å—Ç–µ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "371c0896-4b67-4a54-a121-e4fade5a0c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ 30 —Ç–µ–≥–∞—Ö...\n",
      "–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏:\n",
      "  y_manual_valid: (127, 30)\n",
      "  y_pred_baseline: (127, 30)\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∞ F-beta –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ - 0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "print(f\"\\n–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ {len(valid_tags_indices)} —Ç–µ–≥–∞—Ö...\")\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "\n",
    "# 6. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º\n",
    "y_pred_baseline = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏:\")\n",
    "print(f\"  y_manual_valid: {y_manual_valid.shape}\")\n",
    "print(f\"  y_pred_baseline: {y_pred_baseline.shape}\")\n",
    "\n",
    "# 7. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫—É\n",
    "baseline_score = fbeta_score(y_manual_valid, y_pred_baseline, beta=0.5, zero_division=0, average='samples')\n",
    "print(f'\\n–ú–µ—Ç—Ä–∏–∫–∞ F-beta –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ - {baseline_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a413b4f-0a51-4571-91c4-cff45704d0fe",
   "metadata": {},
   "source": [
    "# –û–±—â–∏–µ —Ç–µ–≥–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f94e901-b064-464b-8504-dbe8d08576d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—â–∏—Ö —Ç–µ–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: 21\n",
      "–û–±—â–∏–µ —Ç–µ–≥–∏: ['–ë—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è', '–í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞', '–î–æ–ª–≥–æ–ø—Ä—É–¥–Ω—ã–π —Å–∫–ª–∞–¥', '–î–æ—Å—Ç–∞–≤–∫–∞', '–ñ–∞–ª–æ–±—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É', '–ó–∞–∫—Ä—ã–≤–∞—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã', '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª—É', '–ù–µ—Ç —Ç–æ–≤–∞—Ä–∞/—É—Å–ª—É–≥–∏', '–ù–µ—Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä', '–û–ø–ª–∞—Ç–∞', '–ü—Ä–µ—Ç–µ–Ω–∑–∏—è', '–†–µ–≥–∏–æ–Ω', '–†–æ—Å—Ç–æ–≤ —Å–∫–ª–∞–¥', '–°–∞–º–æ–≤—ã–≤–æ–∑', '–¢–æ—Ä–≥—É–µ—Ç—Å—è', '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è', '–§–∞–º–∏–ª–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤', '–ß–∞—Å—ã —Ä–∞–±–æ—Ç—ã', '–®—É—à–∞—Ä—ã —Å–∫–ª–∞–¥', '–≠–î–û', '–≠–∫—Å–ø—Ä–µ—Å—Å - –¥–æ—Å—Ç–∞–≤–∫–∞']\n",
      "–ú–µ—Ç—Ä–∏–∫–∞ F-beta –Ω–∞ –æ–±—â–∏—Ö —Ç–µ–≥–∞—Ö - 0.27\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Ö–æ–¥–∏–º —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –û–ë–û–ò–• –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "common_tags_indices = []\n",
    "for i in range(y_auto.shape[1]):\n",
    "    # –¢–µ–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏ –≤ train –∏ –≤ test, –∏ –∏–º–µ—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ train\n",
    "    if y_auto[:, i].sum() >= 2 and y_manual[:, i].sum() >= 2:\n",
    "        common_tags_indices.append(i)\n",
    "\n",
    "print(f\"–û–±—â–∏—Ö —Ç–µ–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {len(common_tags_indices)}\")\n",
    "\n",
    "common_tags = [mlb_classes[i] for i in common_tags_indices]\n",
    "print(\"–û–±—â–∏–µ —Ç–µ–≥–∏:\", common_tags)\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "y_auto_common = y_auto[:, common_tags_indices]\n",
    "y_manual_common = y_manual[:, common_tags_indices]\n",
    "\n",
    "# –û–±—É—á–∞–µ–º –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_common)\n",
    "y_pred_baseline = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "baseline_score = fbeta_score(y_manual_common, y_pred_baseline, beta=0.5, zero_division=0, average='samples')\n",
    "print(f'–ú–µ—Ç—Ä–∏–∫–∞ F-beta –Ω–∞ –æ–±—â–∏—Ö —Ç–µ–≥–∞—Ö - {baseline_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b00e80-1e66-4dad-abe8-4aa9c61d78c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d594af8-1ac6-470e-a0f8-635a88c9a618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff48b5-1860-4a53-8530-470363d2194c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355d047-dbb8-48c7-b178-3baabe022c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9555e-a02f-4b03-84c0-d8bfb1137b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28680a17-fde8-4ce4-8e29-ef3a49e04da0",
   "metadata": {},
   "source": [
    "print('\\n=== –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ===')\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤\n",
    "print('–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:')\n",
    "tag_counts = y_auto.sum(axis=0)\n",
    "valid_tags_indices = []\n",
    "\n",
    "for i, (tag, count) in enumerate(zip(tags_list, tag_counts)):\n",
    "    print(f'  {tag}: {count} –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
    "    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏ —Å —Ö–æ—Ç—è –±—ã 2 –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "    if count > 1 and count < len(y_auto) - 1:\n",
    "        valid_tags_indices.append(i)\n",
    "\n",
    "print(f'–ò–∑ {len(tags_list)} —Ç–µ–≥–æ–≤ {len(valid_tags_indices)} –ø—Ä–∏–≥–æ–¥–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "tags_list_valid = [tags_list[i] for i in valid_tags_indices]\n",
    "\n",
    "print(f'–ë—É–¥–µ–º –æ–±—É—á–∞—Ç—å –Ω–∞ {len(tags_list_valid)} —Ç–µ–≥–∞—Ö')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –¥—Ä—É–≥–∏–º —Ä–µ—à–∞—Ç–µ–ª–µ–º\n",
    "base_classifier = LogisticRegression(\n",
    "    C=15,              # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    solver='lbfgs',     # –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "    max_iter=1000,      # –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "    random_state=42,    # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    verbose=1           # –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è\n",
    ")\n",
    "\n",
    "# –ú—É–ª—å—Ç–∏-–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "multi_label_model = MultiOutputClassifier(base_classifier, n_jobs=-1)\n",
    "\n",
    "print('–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...')\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "print('–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ')\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–≥–∞—Ö\n",
    "valid_tags_info = {\n",
    "    'indices': valid_tags_indices,\n",
    "    'tags': tags_list_valid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b2ffa-ead4-460b-bf8f-8b76735ce196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95108f98-92b5-4def-b4de-f636d7d15eee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –ù–µ —Ä–∞–±–æ—Ç–∞—Ç–µ –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –º—É–ª—å—Ç–∏–ª–∞–±–µ–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07429a7-d8e0-490d-ab07-3ef5a3772a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fab21-367f-43cf-828d-7ccf2dccc56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "base_classifier = LogisticRegression(\n",
    "    C=15,               # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    solver='lbfgs',     # –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º\n",
    "    max_iter=1000,      # –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "    random_state=RANDOM_STATE,    # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    verbose=0,           # –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# –ú—É–ª—å—Ç–∏-–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "multi_label_model = MultiOutputClassifier(base_classifier, n_jobs=-1)\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "\n",
    "fbeta_05 = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "cv_base = cross_val_score(\n",
    "    multi_label_model,\n",
    "    X_train_tfidf,\n",
    "    y_auto_valid,\n",
    "    # —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "    cv=KFold(5, shuffle=True, random_state=RANDOM_STATE),\n",
    "    scoring=fbeta_05\n",
    ").mean()\n",
    "\n",
    "print(f'–ú–µ—Ç—Ä–∏–∫–∞ F1-macro –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ - {cv_base:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c776f-2489-4f0b-8a3e-038e7fe1c71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cb9ba31-2140-442c-9f1a-482c0f2c9aeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –ü–æ—Ä–æ–≥ –¥–ª—è –∑–∞–∫–∞–∑—á–∏–∫–∞, –ª—É—á—à–µ –ø—Ä–æ–ø—É—Å–∫–∏—Ç—å –Ω–µ–∂–µ–ª–∏ –≤—ã–¥–∞—Ç—å –ª–∏—à–Ω–∏–π —Ç–µ–≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1012a7-6f83-442a-ad8c-8ed3a69e2bf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "–ü–æ–Ω—è–ª! **–ï—Å–ª–∏ –≤–∞–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ–≥, –∞ –Ω–µ —É–∫–∞–∑–∞—Ç—å –ª–∏—à–Ω–∏–π** - —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ **False Positive (–ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è) –¥–æ—Ä–æ–∂–µ —á–µ–º False Negative (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏)**. \n",
    "\n",
    "–í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –Ω–∞–º –Ω—É–∂–µ–Ω **–±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥**! üéØ\n",
    "\n",
    "## üö® **–°–¢–†–ê–¢–ï–ì–ò–Ø –î–õ–Ø –í–ê–®–ï–ì–û –°–õ–£–ß–ê–Ø:**\n",
    "\n",
    "### **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –í–´–°–û–ö–ò–ô –ø–æ—Ä–æ–≥ (0.7-0.9)**\n",
    "```python\n",
    "# –í–ê–®–ê –°–¢–†–ê–¢–ï–ì–ò–Ø: –ª—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ–≥, —á–µ–º –ø—Ä–∏—Å–≤–æ–∏—Ç—å –ª–∏—à–Ω–∏–π\n",
    "# ‚Üí –ò—Å–ø–æ–ª—å–∑—É–µ–º –í–´–°–û–ö–ò–ô –ø–æ—Ä–æ–≥ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è False Positive\n",
    "\n",
    "recommended_threshold = 0.7  # –∏–ª–∏ –¥–∞–∂–µ 0.8\n",
    "```\n",
    "\n",
    "### **–ü–æ—á–µ–º—É –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥:**\n",
    "- **‚úÖ –ú–µ–Ω—å—à–µ False Positive** - –º–µ–Ω—å—à–µ –ª–∏—à–Ω–∏—Ö —Ç–µ–≥–æ–≤\n",
    "- **‚úÖ –í—ã—à–µ Precision** - –∫–æ–≥–¥–∞ —Ç–µ–≥ –ø—Ä–∏—Å–≤–æ–µ–Ω, –æ–Ω —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π  \n",
    "- **‚ö†Ô∏è –ë–æ–ª—å—à–µ False Negative** - –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–≥–∏ –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã (—ç—Ç–æ acceptable –ø–æ –≤–∞—à–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º)\n",
    "\n",
    "## üîß **–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –î–õ–Ø –í–ê–®–ï–ì–û –°–õ–£–ß–ê–Ø:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–û–†–û–ì–ê –î–õ–Ø –ú–ò–ù–ò–ú–ò–ó–ê–¶–ò–ò FALSE POSITIVE\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–û–†–û–ì–ê –î–õ–Ø –ú–ò–ù–ò–ú–ò–ó–ê–¶–ò–ò FALSE POSITIVE ===')\n",
    "\n",
    "def optimize_threshold_for_precision(model, X_test, y_test):\n",
    "    \"\"\"–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Ä–æ–≥ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ False Positive\"\"\"\n",
    "    best_threshold = 0.7  # –ù–∞—á–∏–Ω–∞–µ–º —Å –≤—ã—Å–æ–∫–æ–≥–æ –ø–æ—Ä–æ–≥–∞\n",
    "    best_f05 = 0\n",
    "    \n",
    "    print('–ü–æ–∏—Å–∫ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ False Positive...')\n",
    "    print('–ü–æ—Ä–æ–≥ | Precision | Recall | F-0.5')\n",
    "    print('-' * 40)\n",
    "    \n",
    "    # –ü—Ä–æ–±—É–µ–º –í–´–°–û–ö–ò–ï –ø–æ—Ä–æ–≥–∏\n",
    "    for threshold in [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]:\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        y_pred_proba_matrix = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "        y_pred = (y_pred_proba_matrix >= threshold).astype(int)\n",
    "        \n",
    "        f05_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        \n",
    "        for i in range(y_test.shape[1]):\n",
    "            if len(np.unique(y_test[:, i])) > 1:\n",
    "                precision = precision_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "                recall = recall_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "                f05 = fbeta_score(y_test[:, i], y_pred[:, i], beta=0.5, zero_division=0)\n",
    "                \n",
    "                f05_scores.append(f05)\n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "        \n",
    "        current_f05 = np.mean(f05_scores) if f05_scores else 0\n",
    "        avg_precision = np.mean(precision_scores) if precision_scores else 0\n",
    "        avg_recall = np.mean(recall_scores) if recall_scores else 0\n",
    "        \n",
    "        print(f'{threshold:.2f}   | {avg_precision:.3f}    | {avg_recall:.3f}  | {current_f05:.3f}')\n",
    "        \n",
    "        if current_f05 > best_f05:\n",
    "            best_f05 = current_f05\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_f05\n",
    "\n",
    "best_threshold, best_f05 = optimize_threshold_for_precision(final_multilabel_model, X_test_final, y_test_eval)\n",
    "print(f'\\n‚úÖ –†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–ù–´–ô –ü–û–†–û–ì: {best_threshold:.2f}')\n",
    "print(f'‚úÖ F-0.5: {best_f05:.4f}')\n",
    "```\n",
    "\n",
    "## üìä **–ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –° –í–´–°–û–ö–ò–ú –ü–û–†–û–ì–û–ú:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# –ê–ù–ê–õ–ò–ó –° –í–´–°–û–ö–ò–ú –ü–û–†–û–ì–û–ú\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –° –í–´–°–û–ö–ò–ú –ü–û–†–û–ì–û–ú ===')\n",
    "\n",
    "def analyze_high_threshold(model, X_test, y_test, threshold, test_valid_tags):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º\"\"\"\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    y_pred_proba_matrix = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "    y_pred = (y_pred_proba_matrix >= threshold).astype(int)\n",
    "    \n",
    "    print(f'–ê–ù–ê–õ–ò–ó –î–õ–Ø –ü–û–†–û–ì–ê {threshold}:')\n",
    "    print('–¢–µ–≥ | Precision | Recall | F-0.5 | Predicted%')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    total_predicted = 0\n",
    "    total_possible = 0\n",
    "    \n",
    "    for i, tag in enumerate(test_valid_tags):\n",
    "        if len(np.unique(y_test[:, i])) > 1:\n",
    "            precision = precision_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "            recall = recall_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "            f05 = fbeta_score(y_test[:, i], y_pred[:, i], beta=0.5, zero_division=0)\n",
    "            \n",
    "            predicted_ratio = np.sum(y_pred[:, i]) / len(y_pred[:, i])\n",
    "            \n",
    "            print(f'{tag[:15]:15} | {precision:.3f}    | {recall:.3f}  | {f05:.3f}  | {predicted_ratio:.1%}')\n",
    "            \n",
    "            total_predicted += np.sum(y_pred[:, i])\n",
    "            total_possible += np.sum(y_test[:, i])\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(f'–û–±—â–µ–µ: Precision ~ –≤—ã—Å–æ–∫–æ–µ, Recall ~ —Å—Ä–µ–¥–Ω–µ–µ')\n",
    "    print(f'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ —Ç–µ–≥–æ–≤: {total_predicted} –∏–∑ {total_possible} –≤–æ–∑–º–æ–∂–Ω—ã—Ö')\n",
    "\n",
    "analyze_high_threshold(final_multilabel_model, X_test_final, y_test_eval, best_threshold, test_valid_tags)\n",
    "```\n",
    "\n",
    "## üéØ **–§–ò–ù–ê–õ–¨–ù–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# –§–ò–ù–ê–õ–¨–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê –î–õ–Ø –í–ê–®–ï–ì–û –°–õ–£–ß–ê–Ø\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø ===')\n",
    "\n",
    "# –î–ª—è –≤–∞—à–µ–≥–æ —Å–ª—É—á–∞—è: \"–≤–∞–∂–Ω–µ–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ–≥, —á–µ–º —É–∫–∞–∑–∞—Ç—å –ª–∏—à–Ω–∏–π\"\n",
    "# –†–µ–∫–æ–º–µ–Ω–¥—É—é –ø–æ—Ä–æ–≥ 0.7-0.8\n",
    "\n",
    "if best_threshold >= 0.7:\n",
    "    final_threshold = best_threshold\n",
    "    print(f'‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {final_threshold:.2f}')\n",
    "else:\n",
    "    final_threshold = 0.75  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥\n",
    "    print(f'‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥: {final_threshold:.2f}')\n",
    "    print('   (–¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)')\n",
    "\n",
    "# –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–µ—Ç—Ä–∏–∫—É\n",
    "final_f05, final_per_class_f05 = evaluate_f05_macro(\n",
    "    final_multilabel_model, \n",
    "    X_test_final, \n",
    "    y_test_eval,\n",
    "    threshold=final_threshold\n",
    ")\n",
    "\n",
    "print(f'\\nüéØ –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:')\n",
    "print(f'–ü–æ—Ä–æ–≥: {final_threshold:.2f}')\n",
    "print(f'F-0.5: {final_f05:.4f}')\n",
    "\n",
    "print('\\nüìä –ü–æ —Ç–µ–≥–∞–º:')\n",
    "for tag, score in zip(test_valid_tags, final_per_class_f05):\n",
    "    print(f'  {tag}: {score:.4f}')\n",
    "```\n",
    "\n",
    "## üíæ **–°–û–•–†–ê–ù–ï–ù–ò–ï –° –í–´–°–û–ö–ò–ú –ü–û–†–û–ì–û–ú:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –í–´–°–û–ö–ò–ú –ü–û–†–û–ì–û–ú\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò ===')\n",
    "\n",
    "model_artifacts = {\n",
    "    'tfidf_vectorizer': final_tfidf,\n",
    "    'model': final_multilabel_model,\n",
    "    'tags_list': tags_list,\n",
    "    'valid_tags_indices': valid_tags_indices,\n",
    "    'best_tfidf_params': best_params,\n",
    "    'threshold': final_threshold,  # –í–ê–ñ–ù–û: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥!\n",
    "    'final_f05_score': final_f05,\n",
    "    'strategy': 'high_threshold_minimize_fp',  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n",
    "    'test_valid_tags': test_valid_tags,\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, 'high_precision_model.joblib')\n",
    "print('‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ False Positive')\n",
    "\n",
    "print(f'''\n",
    "üéØ –ò–¢–û–ì–ò –î–õ–Ø –í–ê–®–ï–ô –°–¢–†–ê–¢–ï–ì–ò–ò:\n",
    "‚Ä¢ –ü–æ—Ä–æ–≥: {final_threshold:.2f} (–≤—ã—Å–æ–∫–∏–π –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –ª–æ–∂–Ω—ã—Ö —Ç–µ–≥–æ–≤)\n",
    "‚Ä¢ F-0.5: {final_f05:.4f}\n",
    "‚Ä¢ –°—Ç—Ä–∞—Ç–µ–≥–∏—è: \"–õ—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ–≥, —á–µ–º –ø—Ä–∏—Å–≤–æ–∏—Ç—å –ª–∏—à–Ω–∏–π\"\n",
    "‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç: –ú–µ–Ω—å—à–µ False Positive, –≤—ã—à–µ Precision\n",
    "''')\n",
    "```\n",
    "\n",
    "**–ò—Ç–æ–≥:** –î–ª—è –≤–∞—à–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º **–ø–æ—Ä–æ–≥ 0.7-0.8** - —ç—Ç–æ –¥–∞—Å—Ç –º–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –≤ —É—â–µ—Ä–± –ø–æ–ª–Ω–æ—Ç–µ, —á—Ç–æ exactly —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º! üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d04f83-acef-453d-9f95-39c16f5970ba",
   "metadata": {},
   "source": [
    "# –°–ª–æ–∂–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694397e-61ca-4f6d-8344-622c2e5cfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ y_auto_valid —Å —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º–∏ —Ç–µ–≥–∞–º–∏\n",
    "# –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º valid_tags_indices –∏ y_auto_valid\n",
    "tag_counts = y_auto.sum(axis=0)\n",
    "valid_tags_indices = []\n",
    "\n",
    "print('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –≤ y_auto:')\n",
    "for i, (tag, count) in enumerate(zip(tags_list, tag_counts)):\n",
    "    print(f'  {tag}: {count} –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
    "    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏ —Å —Ö–æ—Ç—è –±—ã 2 –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "    if count > 1 and count < len(y_auto) - 1:\n",
    "        valid_tags_indices.append(i)\n",
    "        \n",
    "print(f'\\n')\n",
    "print(f'–ò–∑ {len(tags_list)} —Ç–µ–≥–æ–≤ {len(valid_tags_indices)} –ø—Ä–∏–≥–æ–¥–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')\n",
    "print(f'\\n')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "tags_list_valid = [tags_list[i] for i in valid_tags_indices]\n",
    "print(f'y_auto_valid shape: {y_auto_valid.shape}')\n",
    "print(f'–ë—É–¥–µ–º –æ–±—É—á–∞—Ç—å –Ω–∞ {len(tags_list_valid)} —Ç–µ–≥–∞—Ö: {tags_list_valid}')\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ –ø–µ—Ä–≤—ã—Ö 5 —Ç–µ–≥–∞—Ö\n",
    "print('\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ –ø–µ—Ä–≤—ã—Ö 5 —Ç–µ–≥–∞—Ö y_auto_valid:')\n",
    "for i in range(min(5, y_auto_valid.shape[1])):\n",
    "    unique, counts = np.unique(y_auto_valid[:, i], return_counts=True)\n",
    "    ratio = counts[1] / sum(counts) if len(counts) > 1 else 0\n",
    "    print(f'  –¢–µ–≥ {i} ({tags_list_valid[i]}): {dict(zip(unique, counts))}, positive ratio: {ratio:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cbba5-1146-45a0-b0e3-39e160d09775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b75c00-4f9a-44ba-8344-ba8e211590cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c2cde-0404-438e-8334-9370222729ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bfa46-ff6c-4357-9f7c-6a4e2bfd557a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4fd1e-cbaa-4377-8251-5cf38e768bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5876804-1faf-40ea-b272-c803f9a8492b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d9b33-6708-40c8-852e-fe1cc5e1fcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77eaf1-effa-4020-8c97-c4c0babf7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º TF-IDF —Ñ–∏—á–∏\n",
    "print('\\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ TF-IDF —Ñ–∏—á:')\n",
    "feature_names = simple_tfidf.get_feature_names_out()\n",
    "print(f\"   –í—Å–µ–≥–æ —Ñ–∏—á: {len(feature_names)}\")\n",
    "print(f\"   –ü—Ä–∏–º–µ—Ä—ã —Ñ–∏—á: {feature_names[:20]}\")\n",
    "\n",
    "# 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–∞—Ö\n",
    "print('\\n3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤:')\n",
    "test_keywords = ['–¥–æ—Å—Ç–∞–≤–∫', '–æ–ø–ª–∞—Ç', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–ø—Ä–µ—Ç–µ–Ω–∑–∏']  # –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏\n",
    "for keyword in test_keywords:\n",
    "    count = sum(1 for text in calls_auto['lemmatized_text'] if keyword in text.lower())\n",
    "    print(f\"   '{keyword}': –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ {count} —Ç–µ–∫—Å—Ç–∞—Ö\")\n",
    "\n",
    "# 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞—Ç—Ä–∏—Ü—É TF-IDF\n",
    "print('\\n4. –ü—Ä–æ–≤–µ—Ä–∫–∞ TF-IDF –º–∞—Ç—Ä–∏—Ü—ã:')\n",
    "print(f\"   X_simple shape: {X_simple.shape}\")\n",
    "print(f\"   Non-zero elements: {X_simple.nnz}\")\n",
    "print(f\"   Sparsity: {1 - X_simple.nnz / (X_simple.shape[0] * X_simple.shape[1]):.3f}\")\n",
    "\n",
    "# 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω —Ç–µ–≥ –¥–µ—Ç–∞–ª—å–Ω–æ\n",
    "if y_auto_valid.shape[1] > 0:\n",
    "    print('\\n5. –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤–æ–≥–æ —Ç–µ–≥–∞:')\n",
    "    y_test_tag = y_auto_valid[:, 0]\n",
    "    unique, counts = np.unique(y_test_tag, return_counts=True)\n",
    "    print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {dict(zip(unique, counts))}\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    dummy = DummyClassifier(strategy='stratified')\n",
    "    dummy_score = cross_val_score(\n",
    "        dummy, X_simple[:500], y_test_tag[:500],\n",
    "        cv=3, scoring=f05_scorer, n_jobs=1\n",
    "    )\n",
    "    print(f\"   Dummy classifier F-0.5: {np.mean(dummy_score):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4eaec4-ff2d-4dc6-bab4-6d086698db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø TF-IDF –î–õ–Ø LOGISTICREGRESSION –° –î–ò–ê–ì–ù–û–°–¢–ò–ö–û–ô\n",
    "# =============================================================================\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print('\\n=== –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø TF-IDF –î–õ–Ø LOGISTICREGRESSION ===')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π scorer –¥–ª—è F-0.5 macro\n",
    "f05_scorer = make_scorer(fbeta_score, beta=0.5, average='macro', zero_division=0)\n",
    "\n",
    "# StratifiedKFold –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def tfidf_logreg_objective_with_debug(trial):\n",
    "    \"\"\"\n",
    "    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ TF-IDF —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π\n",
    "    \"\"\"\n",
    "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã TF-IDF –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "    tfidf_params = {\n",
    "        'max_features': trial.suggest_categorical('max_features', [3000, 5000, 7000]),\n",
    "        'min_df': trial.suggest_int('min_df', 2, 4),  # –£–º–µ–Ω—å—à–∏–ª –¥–∏–∞–ø–∞–∑–æ–Ω\n",
    "        'max_df': trial.suggest_float('max_df', 0.75, 0.9),  # –£–≤–µ–ª–∏—á–∏–ª –º–∏–Ω–∏–º—É–º\n",
    "        'ngram_range': (1, trial.suggest_int('ngram_max', 1, 2)),\n",
    "        'sublinear_tf': trial.suggest_categorical('sublinear_tf', [True, False]),\n",
    "        'use_idf': trial.suggest_categorical('use_idf', [True, False]),\n",
    "    }\n",
    "    \n",
    "    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LogisticRegression\n",
    "    logreg_params = {\n",
    "        'C': 1.0,\n",
    "        'solver': 'liblinear',\n",
    "        'max_iter': 1000,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'class_weight': 'balanced'  # –î–û–ë–ê–í–ò–õ –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # –°–æ–∑–¥–∞–µ–º TF-IDF —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "        tfidf = TfidfVectorizer(\n",
    "            **tfidf_params,\n",
    "            stop_words=russian_stopwords,\n",
    "            lowercase=True,\n",
    "            smooth_idf=True,\n",
    "            token_pattern=r'(?u)\\b\\w{2,}\\b',  # –£–ú–ï–ù–¨–®–ò–õ –¥–æ 2 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            norm='l2'\n",
    "        )\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        X_tfidf = tfidf.fit_transform(calls_auto['lemmatized_text'])\n",
    "        \n",
    "        print(f\"  Trial {trial.number}: TF-IDF shape = {X_tfidf.shape}\")\n",
    "        \n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ë–û–õ–¨–®–ï –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        n_samples = min(2000, X_tfidf.shape[0])  # –£–í–ï–õ–ò–ß–ò–õ –¥–æ 2000\n",
    "        X_subset = X_tfidf[:n_samples]\n",
    "        y_subset = y_auto_valid[:n_samples]\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º LogisticRegression –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "        logreg = LogisticRegression(**logreg_params)\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–≥–∞—Ö —Å F-0.5 –º–µ—Ç—Ä–∏–∫–æ–π\n",
    "        scores = []\n",
    "        n_tags_to_evaluate = min(3, y_subset.shape[1])  # –£–ú–ï–ù–¨–®–ò–õ –¥–æ 3 —Ç–µ–≥–æ–≤\n",
    "        \n",
    "        for i in range(n_tags_to_evaluate):\n",
    "            unique_classes = np.unique(y_subset[:, i])\n",
    "            if len(unique_classes) > 1:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –æ–±–∞ –∫–ª–∞—Å—Å–∞\n",
    "                class_ratio = np.sum(y_subset[:, i]) / len(y_subset[:, i])\n",
    "                print(f\"    Tag {i}: classes {unique_classes}, positive ratio: {class_ratio:.3f}\")\n",
    "                \n",
    "                score = cross_val_score(\n",
    "                    logreg, X_subset, y_subset[:, i],\n",
    "                    cv=skf, scoring=f05_scorer, n_jobs=1\n",
    "                )\n",
    "                scores.append(np.mean(score))\n",
    "                print(f\"    Tag {i} F-0.5: {np.mean(score):.4f}\")\n",
    "        \n",
    "        final_score = np.mean(scores) if scores else 0.0\n",
    "        print(f\"  Trial {trial.number} FINAL SCORE: {final_score:.4f}\")\n",
    "        \n",
    "        return final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Trial {trial.number} ERROR: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–•\n",
    "print('=== –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–• ===')\n",
    "print(f\"calls_auto shape: {calls_auto.shape}\")\n",
    "print(f\"y_auto shape: {y_auto.shape}\")\n",
    "print(f\"y_auto_valid shape: {y_auto_valid.shape}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ–≥–æ–≤\n",
    "print('\\n–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –≤ y_auto_valid:')\n",
    "for i in range(min(5, y_auto_valid.shape[1])):\n",
    "    unique, counts = np.unique(y_auto_valid[:, i], return_counts=True)\n",
    "    print(f\"  –¢–µ–≥ {i}: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é\n",
    "print('\\n=== –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò ===')\n",
    "\n",
    "study_tfidf = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "# –ó–ê–ü–£–°–ö–ê–ï–ú –ú–ï–ù–¨–®–ï TRIALS –î–õ–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò\n",
    "study_tfidf.optimize(tfidf_logreg_objective_with_debug, n_trials=5, show_progress_bar=True)\n",
    "\n",
    "# –í–´–í–û–î–ò–ú –¢–ê–ë–õ–ò–¶–£ –° –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò\n",
    "print('\\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò TF-IDF ===')\n",
    "\n",
    "if study_tfidf.best_value > 0:\n",
    "    result_study = pd.DataFrame({\n",
    "        '–ü–∞—Ä–∞–º–µ—Ç—Ä': study_tfidf.best_params.keys(),\n",
    "        '–ó–Ω–∞—á–µ–Ω–∏–µ': study_tfidf.best_params.values()\n",
    "    }).set_index('–ü–∞—Ä–∞–º–µ—Ç—Ä')\n",
    "\n",
    "    display(result_study)\n",
    "    print(f\"–õ—É—á—à–∞—è –º–µ—Ç—Ä–∏–∫–∞ F-0.5: {study_tfidf.best_value:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ –¥–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü—Ä–æ–±–ª–µ–º–∞ –≤ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13df559-0620-46ea-ba57-8aaf0b6d31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# –ü–ï–†–ï–°–û–ó–î–ê–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò –ò –û–¶–ï–ù–ö–ê\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== –ü–ï–†–ï–°–û–ó–î–ê–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò ===')\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ Optuna\n",
    "best_params = study_tfidf.best_params\n",
    "\n",
    "print('–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã TF-IDF:')\n",
    "for param, value in best_params.items():\n",
    "    print(f'  {param}: {value}')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä\n",
    "final_tfidf = TfidfVectorizer(\n",
    "    max_features=best_params['max_features'],\n",
    "    min_df=best_params['min_df'],\n",
    "    max_df=best_params['max_df'],\n",
    "    ngram_range=(1, best_params['ngram_max']),\n",
    "    sublinear_tf=best_params['sublinear_tf'],\n",
    "    use_idf=best_params['use_idf'],\n",
    "    stop_words=russian_stopwords,\n",
    "    lowercase=True,\n",
    "    smooth_idf=True,\n",
    "    token_pattern=r'(?u)\\b\\w{2,}\\b',\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "# –û–±—É—á–∞–µ–º TF-IDF –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "print('\\n–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ TF-IDF...')\n",
    "X_train_final = final_tfidf.fit_transform(calls_auto['lemmatized_text'])\n",
    "X_test_final = final_tfidf.transform(calls_manual['lemmatized_text'])\n",
    "\n",
    "print(f'–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å train: {X_train_final.shape}')\n",
    "print(f'–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å test: {X_test_final.shape}')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å\n",
    "final_logreg = LogisticRegression(\n",
    "    C=1.0,\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "final_multilabel_model = MultiOutputClassifier(final_logreg, n_jobs=1)\n",
    "\n",
    "print('–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π LogisticRegression –º–æ–¥–µ–ª–∏...')\n",
    "final_multilabel_model.fit(X_train_final, y_auto_valid)\n",
    "print('–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410fa9a-d7c6-43ac-9cf3-5bf9349a54d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca6f9a-0216-48c9-99ad-4f48f7dadd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505acc62-ae66-4f48-bd1a-9b906dd2bf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57547ccb-9ff4-4292-892b-99c1153af80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47ecae-b220-4a2a-b3fe-a1787879c7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f754a-a512-4aaf-bdce-4b5bfde52e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85453f0d-bd02-43a8-a1dc-2f1948d60cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç–æ–ø-—Å–ª–æ–≤ –≤ —Å–ø–∏—Å–æ–∫\n",
    "russian_stopwords = list(russian_stopwords)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,               # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á\n",
    "    min_df=5,                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞\n",
    "    max_df=0.8,                      # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞  \n",
    "    stop_words=russian_stopwords,    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "    ngram_range=(1, 3),              # –£–Ω–∏–≥—Ä–∞–º–º—ã –∏ —Ç—Ä–∏–≥—Ä–∞–º–º—ã\n",
    "    lowercase=True,                  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    use_idf=True,                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º IDF –≤–µ—Å–∞\n",
    "    sublinear_tf=True,               # –°—É–±–ª–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ TF\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b', # –°–ª–æ–≤–∞ –æ—Ç 3 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    strip_accents='unicode',         # –£–¥–∞–ª–µ–Ω–∏–µ –∞–∫—Ü–µ–Ω—Ç–æ–≤\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a80bc-0565-411f-a186-a7b757f9cf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8769b-a724-4fbf-842f-26324c756b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16725157-68a5-45be-8e78-df3c4ca11582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–ò–ù–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ù–ê–®–ï–ì–û –ü–†–û–ï–ö–¢–ê\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    stop_words=russian_stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True,\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a6aca-8300-40d6-aa6f-099e29000660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò TF-IDF –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –¢–ï–õ–ï–§–û–ù–ù–´–• –†–ê–ó–ì–û–í–û–†–û–í\n",
    "# =============================================================================\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    # === –û–°–ù–û–í–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ ===\n",
    "    max_features=5000,              # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    min_df=3,                       # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è < 3 —Ä–∞–∑\n",
    "    max_df=0.8,                     # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞ –≤ >80% –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "    \n",
    "    # === –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–ê ===\n",
    "    stop_words=russian_stopwords,   # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "    ngram_range=(1, 2),             # –£–Ω–∏–≥—Ä–∞–º–º—ã + –±–∏–≥—Ä–∞–º–º—ã\n",
    "    lowercase=True,                 # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b', # –°–ª–æ–≤–∞ –æ—Ç 3 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    \n",
    "    # === TF-IDF –í–ï–°–ê ===\n",
    "    use_idf=True,                   # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å IDF –≤–µ—Å–∞\n",
    "    smooth_idf=True,                # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ IDF\n",
    "    sublinear_tf=True,              # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ TF\n",
    "    \n",
    "    # === –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê ===\n",
    "    analyzer='word',                # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–ª–æ–≤–∞–º\n",
    "    norm='l2',                      # L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤\n",
    "    strip_accents='unicode'         # –£–¥–∞–ª–µ–Ω–∏–µ –∞–∫—Ü–µ–Ω—Ç–æ–≤\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b837d-58ff-4e67-842c-35e1b345afaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57139cdc-bdd0-4cbb-a542-6ba873538434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697b571-cd65-4c65-8fa3-2edb74a1cfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f64f60-6acf-41e1-81e1-fe7ed04588c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd7e94-a4ee-4f6d-a269-f744d1f089cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37429753-42eb-438c-a88c-03761738c419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc4c49-4283-45db-9001-438f91207833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289dd10-d81c-4f41-9909-e6cee2a69d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div style=\"border:ridge violet 5px; padding: 30px; border-radius: 15px;\">\n",
    "<h3> –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ <a class=\"tocSkip\"> </h3> \n",
    "\n",
    "–í–æ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ TF-IDF –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏ –∏ –∏—Ö –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò TF-IDF –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –¢–ï–õ–ï–§–û–ù–ù–´–• –†–ê–ó–ì–û–í–û–†–û–í\n",
    "# =============================================================================\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    # === –û–°–ù–û–í–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ ===\n",
    "    max_features=5000,              # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    min_df=3,                       # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è < 3 —Ä–∞–∑\n",
    "    max_df=0.8,                     # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞ –≤ >80% –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "    \n",
    "    # === –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–ê ===\n",
    "    stop_words=russian_stopwords,   # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "    ngram_range=(1, 2),             # –£–Ω–∏–≥—Ä–∞–º–º—ã + –±–∏–≥—Ä–∞–º–º—ã\n",
    "    lowercase=True,                 # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b', # –°–ª–æ–≤–∞ –æ—Ç 3 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    \n",
    "    # === TF-IDF –í–ï–°–ê ===\n",
    "    use_idf=True,                   # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å IDF –≤–µ—Å–∞\n",
    "    smooth_idf=True,                # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ IDF\n",
    "    sublinear_tf=True,              # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ TF\n",
    "    \n",
    "    # === –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê ===\n",
    "    analyzer='word',                # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–ª–æ–≤–∞–º\n",
    "    norm='l2',                      # L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤\n",
    "    strip_accents='unicode'         # –£–¥–∞–ª–µ–Ω–∏–µ –∞–∫—Ü–µ–Ω—Ç–æ–≤\n",
    ")\n",
    "```\n",
    "\n",
    "## üìä **–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫:**\n",
    "\n",
    "### **1. `max_features=5000`**\n",
    "- **–ü–æ—á–µ–º—É**: –ù–∞—à–∏ —Ç–µ–∫—Å—Ç—ã —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏–º–µ—é—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—É—é –ª–µ–∫—Å–∏–∫—É\n",
    "- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ**: –£–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å, —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ, —Å–Ω–∏–∂–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ\n",
    "- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**: 3000-8000 –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "### **2. `min_df=3`, `max_df=0.8`**\n",
    "- **min_df=3**: –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞ (—à—É–º)\n",
    "- **max_df=0.8**: –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ)\n",
    "- **–ü—Ä–∏–º–µ—Ä**: –°–ª–æ–≤–∞ \"–∞–ª–ª–æ\", \"–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\" –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã\n",
    "\n",
    "### **3. `ngram_range=(1, 2)`**\n",
    "- **–£–Ω–∏–≥—Ä–∞–º–º—ã**: \"–¥–æ—Å—Ç–∞–≤–∫–∞\", \"–æ–ø–ª–∞—Ç–∞\"\n",
    "- **–ë–∏–≥—Ä–∞–º–º—ã**: \"—Å—Ä–æ—á–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞\", \"–±–µ–∑–Ω–∞–ª–∏—á–Ω–∞—è –æ–ø–ª–∞—Ç–∞\"\n",
    "- **–ü–æ—á–µ–º—É**: –ë–∏–≥—Ä–∞–º–º—ã —É–ª–∞–≤–ª–∏–≤–∞—é—Ç —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è, –≤–∞–∂–Ω—ã–µ –¥–ª—è —Ç–µ–≥–æ–≤\n",
    "\n",
    "### **4. `sublinear_tf=True`**\n",
    "- **–§–æ—Ä–º—É–ª–∞**: `1 + log(tf)` –≤–º–µ—Å—Ç–æ `tf`\n",
    "- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ**: –£–º–µ–Ω—å—à–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –æ—á–µ–Ω—å —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤\n",
    "- **–ü—Ä–∏–º–µ—Ä**: –°–ª–æ–≤–æ \"–∫–æ–º–ø–∞–Ω–∏—è\" –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è 1000 —Ä–∞–∑ ‚Üí –≤–µ—Å log(1000) ‚âà 3\n",
    "\n",
    "### **5. `token_pattern=r'(?u)\\b\\w{3,}\\b'`**\n",
    "- **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: –¢–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –æ—Ç 3 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "- **–ü–æ—á–µ–º—É**: –£–±–∏—Ä–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (\"–¥–∞\", \"–Ω–µ—Ç\", \"–Ω—É\")\n",
    "- **–†–µ–≥—É–ª—è—Ä–∫–∞**: `(?u)` - unicode, `\\b` - –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤, `\\w{3,}` - 3+ —Å–∏–º–≤–æ–ª–∞\n",
    "\n",
    "## üîß **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:**\n",
    "\n",
    "### **–í–∞—Ä–∏–∞–Ω—Ç A: –î–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (–±–æ–ª—å—à–µ —Ñ–∏—á)**\n",
    "```python\n",
    "tfidf_quality = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    min_df=2,           # –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π\n",
    "    max_df=0.7,         # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π\n",
    "    ngram_range=(1, 3), # + —Ç—Ä–∏–≥—Ä–∞–º–º—ã\n",
    "    analyzer='char_wb', # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º\n",
    "    ngram_range=(2, 4)  # –°–∏–º–≤–æ–ª—å–Ω—ã–µ n-–≥—Ä–∞–º–º—ã\n",
    ")\n",
    "```\n",
    "\n",
    "### **–í–∞—Ä–∏–∞–Ω—Ç B: –î–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (–º–µ–Ω—å—à–µ —Ñ–∏—á)**\n",
    "```python\n",
    "tfidf_fast = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    min_df=5,           # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 1), # –¢–æ–ª—å–∫–æ —É–Ω–∏–≥—Ä–∞–º–º—ã\n",
    "    sublinear_tf=False  # –ë–µ–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    ")\n",
    "```\n",
    "\n",
    "### **–í–∞—Ä–∏–∞–Ω—Ç C: –î–ª—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤**\n",
    "```python\n",
    "tfidf_phone = TfidfVectorizer(\n",
    "    max_features=6000,\n",
    "    min_df=2,\n",
    "    max_df=0.75,\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=r'(?u)\\b\\w{2,}\\b',  # –°–ª–æ–≤–∞ –æ—Ç 2 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    stop_words=extended_stopwords,    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "    vocabulary=domain_vocabulary      # –ü—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    ")\n",
    "```\n",
    "\n",
    "## üéØ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –¥–ª—è –Ω–∞—à–µ–≥–æ —Å–ª—É—á–∞—è:**\n",
    "\n",
    "**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏**, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏:\n",
    "- ‚úÖ –£—á–∏—Ç—ã–≤–∞—é—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫—É —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤\n",
    "- ‚úÖ –ë–∞–ª–∞–Ω—Å–∏—Ä—É—é—Ç –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é\n",
    "- ‚úÖ –£–±–∏—Ä–∞—é—Ç —à—É–º–æ–≤—ã–µ —Å–ª–æ–≤–∞\n",
    "- ‚úÖ –°–æ—Ö—Ä–∞–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ n-–≥—Ä–∞–º–º—ã\n",
    "\n",
    "```python\n",
    "# –§–ò–ù–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ù–ê–®–ï–ì–û –ü–†–û–ï–ö–¢–ê\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    stop_words=russian_stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True,\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b'\n",
    ")\n",
    "```\n",
    "\n",
    "–≠—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–æ–∫–∞–∑–∞–ª–∏ —Å–≤–æ—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏ –¥–æ–ª–∂–Ω—ã –¥–∞—Ç—å —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ —Ä–∞–∑—É–º–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6efcfcb-07f1-4804-8c26-b8411d604f41",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
