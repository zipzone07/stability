{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6211f24-66b8-4069-89aa-178fbced6def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 00:32:52.898329: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759692772.933957   11971 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759692772.985406   11971 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759692773.261928   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759692773.261953   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759692773.261956   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759692773.261958   11971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd # анализ и обработка данных\n",
    "import numpy as np # вычислительная мощ языка С\n",
    "import matplotlib.pyplot as plt # визуализация\n",
    "import seaborn as sns # расширенная визуализация\n",
    "#from datetime import datetime # обработка дат и времени\n",
    "#import re # регулярные выражения\n",
    "from collections import Counter # словарь-подкласс для подсчета хэш данных\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Для векторизации текста\n",
    "from sklearn.model_selection import ( # разделяем данные\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    KFold\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score, \n",
    "    classification_report,\n",
    "    make_scorer\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer # встраивание текста и изображений\n",
    "from sklearn.linear_model import LogisticRegression # базовая модель\n",
    "from sklearn.neural_network import MLPClassifier # \n",
    "from sklearn.multioutput import MultiOutputClassifier # мульти-лейбл классификация\n",
    "import joblib # сохранение модели\n",
    "import warnings # контроль предупреждений\n",
    "warnings.filterwarnings('ignore') # подавить все не крит. предупреждения\n",
    "\n",
    "# Импорт для лемматизации и стоп-слов\n",
    "import spacy\n",
    "import nltk  # лингвистическая обработки\n",
    "from nltk.corpus import stopwords  # стоп-слова\n",
    "from tqdm import tqdm  # прогресс-бары\n",
    "import pickle\n",
    "\n",
    "# Скачиваем стоп-слова\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')  # наличие стоп-слов\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')  # скачиваем если отсутствуют\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4364e28b-3a74-4718-a217-b59949150180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка обработанных данных из этапа 1\n",
    "with open('processed_data.pkl', 'rb') as f:  # Открываем файл для чтения\n",
    "    data = pickle.load(f)  # Загружаем данные\n",
    "\n",
    "# Извлекаем данные из словаря\n",
    "calls_auto = data['calls_auto']  # Тренировочные данные (авторазметка)\n",
    "calls_manual = data['calls_manual']  # Тестовые данные (ручная разметка)\n",
    "y_auto = data['y_auto']  # Целевые переменные тренировочные\n",
    "y_manual = data['y_manual']  # Целевые переменные тестовые\n",
    "tags_list = data['tags_list']  # Список тегов заказчика\n",
    "all_tags = data['all_tags'] # Список всех тегов для обучения\n",
    "employees_list = data['employees_list']  # Список сотрудников\n",
    "competitors_list = ['competitors_list'] # список конкурентов\n",
    "brands_list = data['brands_list']  # Список брендов\n",
    "materials_list = data['materials_list']  # Список материалов\n",
    "mlb_classes = data['mlb_classes']\n",
    "available_in_train = data['available_in_train']  # Теги доступные в трейне\n",
    "available_in_test = data['available_in_test']  # Теги доступные в тесте\n",
    "not_available_in_train = data['not_available_in_train'] # Теги отсутствующие в трейне\n",
    "not_available_in_test = data['not_available_in_test'] # Теги отсутствующие в тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed026ed6-9ec3-4e2b-ad16-d8e345358bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочные данные: 1900 разговоров\n",
      "Тестовые данные: 127 разговоров\n",
      "Всего тегов: 38\n",
      "Тегов для оценки: 27\n",
      "Индексы тегов для оценки: [30, 36, 6, 17, 12, 31, 24, 0, 37, 2, 19, 22, 10, 34, 29, 33, 11, 4, 13, 16, 15, 27, 28, 26, 23, 8, 35]\n"
     ]
    }
   ],
   "source": [
    "print(f'Тренировочные данные: {len(calls_auto)} разговоров')  # Размер тренировочных данных\n",
    "print(f'Тестовые данные: {len(calls_manual)} разговоров')  # Размер тестовых данных\n",
    "print(f'Всего тегов: {len(all_tags)}')  # Общее количество тегов\n",
    "print(f'Тегов для оценки: {len(available_in_test)}')  # Теги с разметкой в тесте\n",
    "\n",
    "# Создаем маски для тегов, которые есть в тестовых данных\n",
    "available_indices = [list(all_tags).index(tag) for tag in available_in_test]  # Индексы доступных тегов\n",
    "available_tags_names = [list(all_tags)[i] for i in available_indices]  # Названия доступных тегов\n",
    "print(f'Индексы тегов для оценки: {available_indices}')  # Выводим индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3511eedd-2f23-4df0-9e95-5b50f2390ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется 156 стоп-слов\n"
     ]
    }
   ],
   "source": [
    "# Базовые стоп-слова из NLTK\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "# Дополняем телефонными выражениями\n",
    "phone_stopwords = {'здравствуйте', 'добрый', 'пожалуйста', 'спасибо', 'алло'}\n",
    "russian_stopwords.update(phone_stopwords)\n",
    "\n",
    "print(f'Используется {len(russian_stopwords)} стоп-слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68f80aa-7340-496f-840d-8fd03450cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем множество стоп-слов в список\n",
    "russian_stopwords = list(russian_stopwords)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,           # Ограничиваем количество фич\n",
    "    min_df=5,                    # Игнорируем редкие слова\n",
    "    max_df=0.8,                 # Игнорируем слишком частые слова  \n",
    "    stop_words=russian_stopwords, # Используем стоп-слова\n",
    "    ngram_range=(1, 3),          # Униграммы и триграммы\n",
    "    lowercase=True,              # Приводим к нижнему регистру\n",
    "    use_idf=True,                # Используем IDF веса\n",
    "    sublinear_tf=True            # Сублинейное масштабирование TF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558b58f1-1894-48d5-8627-6b13a46d445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение TF-IDF...\n",
      "Размерность train: (1900, 5000)\n",
      "Размерность test: (127, 5000)\n",
      "Количество фич: 5000\n"
     ]
    }
   ],
   "source": [
    "# Обучаем TF-IDF на лемматизированных текстах\n",
    "print('Обучение TF-IDF...')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(calls_auto['lemmatized_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(calls_manual['lemmatized_text'])\n",
    "\n",
    "print(f'Размерность train: {X_train_tfidf.shape}')\n",
    "print(f'Размерность test: {X_test_tfidf.shape}')\n",
    "\n",
    "# Анализ фич\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f'Количество фич: {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88dd975-f659-4019-8b7d-552e59b7db54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3de18a-d8ad-403d-9c99-7e7072d01a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Бухгалтерия', 'Высокая цена', 'Долгопрудный склад', 'Доставка',\n",
       "       'Жалобы по качеству', 'Закрывающие документы', 'Заставская офис',\n",
       "       'Карматех/кармапласт', 'Конкуренты', 'Консультация по бренду',\n",
       "       'Консультация по материалу', 'Не торгуется', 'Нет товара/услуги',\n",
       "       'Нецелевой разговор', 'Нецензурное общение',\n",
       "       'Озон/Вб/иные маркетплейсы', 'Оплата', 'Особые условия',\n",
       "       'Отсрочка', 'Офис', 'Пени', 'Претензия', 'Просрочки',\n",
       "       'Разгрузка товара', 'Регион', 'Ростов склад', 'Сайт',\n",
       "       'Сайт vink.ru', 'Самовывоз', 'Судебная претензия', 'Торгуется',\n",
       "       'Транспортная компания', 'Фамилии сотрудников', 'Часы работы',\n",
       "       'Шоурум Елино', 'Шушары склад', 'ЭДО', 'Экспресс - доставка'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f9dd7a-76ca-4224-9719-79b055f4301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ распределения тегов в тренировочных данных:\n",
      "  Закрывающие документы: 868 примеров\n",
      "  Шушары склад: 178 примеров\n",
      "  Сайт vink.ru: 105 примеров\n",
      "  Регион: 538 примеров\n",
      "  Озон/Вб/иные маркетплейсы: 119 примеров\n",
      "  Транспортная компания: 10 примеров\n",
      "  ЭДО: 0 примеров\n",
      "  Высокая цена: 3 примеров\n",
      "  Судебная претензия: 34 примеров\n",
      "  Претензия: 755 примеров\n",
      "  Консультация по материалу: 599 примеров\n",
      "  Нецензурное общение: 2 примеров\n",
      "  Оплата: 208 примеров\n",
      "  Нет товара/услуги: 45 примеров\n",
      "  Сайт: 188 примеров\n",
      "  Консультация по бренду: 30 примеров\n",
      "  Нецелевой разговор: 1899 примеров\n",
      "  Бухгалтерия: 1 примеров\n",
      "  Разгрузка товара: 15 примеров\n",
      "  Жалобы по качеству: 4 примеров\n",
      "  Карматех/кармапласт: 21 примеров\n",
      "  Пени: 10 примеров\n",
      "  Заставская офис: 7 примеров\n",
      "  Шоурум Елино: 24 примеров\n",
      "  Часы работы: 143 примеров\n",
      "  Фамилии сотрудников: 18 примеров\n",
      "  Конкуренты: 320 примеров\n",
      "  Доставка: 0 примеров\n",
      "  Отсрочка: 63 примеров\n",
      "  Самовывоз: 205 примеров\n",
      "  Долгопрудный склад: 186 примеров\n",
      "  Просрочки: 772 примеров\n",
      "  Ростов склад: 81 примеров\n",
      "  Торгуется: 32 примеров\n",
      "  Экспресс - доставка: 2 примеров\n",
      "  Особые условия: 54 примеров\n",
      "  Офис: 4 примеров\n",
      "  Не торгуется: 25 примеров\n",
      "Из 38 тегов 34 пригодны для обучения\n",
      "Будем обучать на 34 тегах\n"
     ]
    }
   ],
   "source": [
    "# Анализируем распределение тегов\n",
    "print('Анализ распределения тегов в тренировочных данных:')\n",
    "tag_counts = y_auto.sum(axis=0)\n",
    "valid_tags_indices = []\n",
    "\n",
    "for i, (tag, count) in enumerate(zip(list(all_tags), tag_counts)):\n",
    "    print(f'  {tag}: {count} примеров')\n",
    "    # Оставляем только теги с хотя бы 2 примерами каждого класса\n",
    "    if count > 1 and count < len(y_auto) - 1:\n",
    "        valid_tags_indices.append(i)\n",
    "\n",
    "print(f'Из {len(list(all_tags))} тегов {len(valid_tags_indices)} пригодны для обучения')\n",
    "\n",
    "# Создаем подвыборку с валидными тегами\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "y_manual_valid = y_manual[:, valid_tags_indices]\n",
    "tags_list_valid = [list(all_tags)[i] for i in valid_tags_indices]\n",
    "\n",
    "print(f'Будем обучать на {len(tags_list_valid)} тегах')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c36cc-886d-4962-8d3d-27b5bb9824a4",
   "metadata": {},
   "source": [
    "# Валидные теги - мой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f786e-2b0d-4c93-8ed8-ff594ba5d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рабочий вариант\n",
    "# 1. Находим индексы валидных тегов (с достаточным количеством примеров)\n",
    "valid_tags_indices = []\n",
    "for i in range(y_auto.shape[1]):\n",
    "    if y_auto[:, i].sum() >= 5:  # или любой другой, например >= 5\n",
    "        valid_tags_indices.append(i)\n",
    "\n",
    "print(f\"Валидных тегов для обучения: {len(valid_tags_indices)}\")\n",
    "\n",
    "# 2. Фильтруем ОБА набора данных по одним и тем же индексам\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "y_manual_valid = y_manual[:, valid_tags_indices]\n",
    "\n",
    "# 3. Получаем названия валидных тегов\n",
    "valid_tags = [mlb_classes[i] for i in valid_tags_indices]\n",
    "print(\"Валидные теги для обучения:\", valid_tags)\n",
    "\n",
    "# 4. Проверяем размерности\n",
    "print(f\"y_auto_valid shape: {y_auto_valid.shape}\")\n",
    "print(f\"y_manual_valid shape: {y_manual_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bce9928-6c17-4546-8a59-adb747793aa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1-macro на тесте - 0.25\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# Создаем базовый классификатор\n",
    "base_classifier = LogisticRegression(\n",
    "    C=15,               # Параметр регуляризации\n",
    "    solver='lbfgs',     # Более стабильный алгоритм\n",
    "    max_iter=1000,      # Максимум итераций\n",
    "    random_state=RANDOM_STATE,    # Для воспроизводимости\n",
    "    verbose=0,           # Прогресс обучения\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Мульти-лейбл классификатор\n",
    "multi_label_model = MultiOutputClassifier(base_classifier, n_jobs=-1)\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "\n",
    "y_pred_baseline = multi_label_model.predict(X_test_tfidf)\n",
    "baseline_score = fbeta_score(y_manual_valid, y_pred_baseline, beta=0.5, zero_division=0, average='samples')\n",
    "\n",
    "print(f'Метрика F1-macro на тесте - {baseline_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ce73a-ab0d-4fef-9de8-2a253ba5653c",
   "metadata": {},
   "source": [
    "# С учетом статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb5b65d-9b27-4f39-8ae0-9cf27e7abfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Теги с недостаточным количеством примеров:\n",
      "  Заставская офис: 0 примеров\n",
      "  Сайт vink.ru: 0 примеров\n",
      "  Особые условия: 1 примеров\n",
      "  Не торгуется: 2 примеров\n",
      "  Шоурум Елино: 2 примеров\n",
      "  Карматех/кармапласт: 3 примеров\n",
      "  Офис: 4 примеров\n",
      "  ЭДО: 4 примеров\n",
      "\n",
      "Всего тегов: 38\n",
      "Валидных тегов (>=5 примеров): 30\n",
      "\n",
      "Теги для обучения: ['Бухгалтерия', 'Высокая цена', 'Долгопрудный склад', 'Доставка', 'Жалобы по качеству', 'Закрывающие документы', 'Конкуренты', 'Консультация по бренду', 'Консультация по материалу', 'Нет товара/услуги', 'Нецелевой разговор', 'Нецензурное общение', 'Озон/Вб/иные маркетплейсы', 'Оплата', 'Отсрочка', 'Пени', 'Претензия', 'Просрочки', 'Разгрузка товара', 'Регион', 'Ростов склад', 'Сайт', 'Самовывоз', 'Судебная претензия', 'Торгуется', 'Транспортная компания', 'Фамилии сотрудников', 'Часы работы', 'Шушары склад', 'Экспресс - доставка']\n",
      "\n",
      "Распределение в тестовых данных:\n",
      "  Бухгалтерия: 18 примеров в тесте\n",
      "  Высокая цена: 3 примеров в тесте\n",
      "  Долгопрудный склад: 5 примеров в тесте\n",
      "  Доставка: 59 примеров в тесте\n",
      "  Жалобы по качеству: 10 примеров в тесте\n",
      "  Закрывающие документы: 8 примеров в тесте\n",
      "  Конкуренты: 0 примеров в тесте\n",
      "  Консультация по бренду: 0 примеров в тесте\n",
      "  Консультация по материалу: 30 примеров в тесте\n",
      "  Нет товара/услуги: 7 примеров в тесте\n",
      "  Нецелевой разговор: 27 примеров в тесте\n",
      "  Нецензурное общение: 0 примеров в тесте\n",
      "  Озон/Вб/иные маркетплейсы: 1 примеров в тесте\n",
      "  Оплата: 30 примеров в тесте\n",
      "  Отсрочка: 0 примеров в тесте\n",
      "  Пени: 0 примеров в тесте\n",
      "  Претензия: 19 примеров в тесте\n",
      "  Просрочки: 1 примеров в тесте\n",
      "  Разгрузка товара: 1 примеров в тесте\n",
      "  Регион: 13 примеров в тесте\n",
      "  Ростов склад: 2 примеров в тесте\n",
      "  Сайт: 0 примеров в тесте\n",
      "  Самовывоз: 4 примеров в тесте\n",
      "  Судебная претензия: 0 примеров в тесте\n",
      "  Торгуется: 2 примеров в тесте\n",
      "  Транспортная компания: 42 примеров в тесте\n",
      "  Фамилии сотрудников: 5 примеров в тесте\n",
      "  Часы работы: 4 примеров в тесте\n",
      "  Шушары склад: 4 примеров в тесте\n",
      "  Экспресс - доставка: 3 примеров в тесте\n"
     ]
    }
   ],
   "source": [
    "# Из вашего вывода видно, что есть теги с 0 примеров в тренировочных данных\n",
    "# Нужно отфильтровать теги, которые невозможно обучить\n",
    "\n",
    "# 1. Анализ тегов с недостаточным количеством примеров\n",
    "tags_with_few_samples = []\n",
    "valid_tags_indices = []\n",
    "\n",
    "for i, tag_name in enumerate(mlb_classes):\n",
    "    count = y_auto[:, i].sum()\n",
    "    if count >= 5:  # минимальное количество примеров для обучения\n",
    "        valid_tags_indices.append(i)\n",
    "    else:\n",
    "        tags_with_few_samples.append((tag_name, count))\n",
    "\n",
    "print(\"Теги с недостаточным количеством примеров:\")\n",
    "for tag, count in sorted(tags_with_few_samples, key=lambda x: x[1]):\n",
    "    print(f\"  {tag}: {count} примеров\")\n",
    "\n",
    "print(f\"\\nВсего тегов: {y_auto.shape[1]}\")\n",
    "print(f\"Валидных тегов (>=5 примеров): {len(valid_tags_indices)}\")\n",
    "\n",
    "# 2. Фильтруем данные\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "y_manual_valid = y_manual[:, valid_tags_indices]\n",
    "\n",
    "# 3. Получаем названия валидных тегов\n",
    "valid_tags = [mlb_classes[i] for i in valid_tags_indices]\n",
    "print(\"\\nТеги для обучения:\", valid_tags)\n",
    "\n",
    "# 4. Проверяем распределение в тестовых данных\n",
    "print(\"\\nРаспределение в тестовых данных:\")\n",
    "for i, tag_name in enumerate(valid_tags):\n",
    "    # Находим исходный индекс тега\n",
    "    original_idx = list(mlb_classes).index(tag_name)\n",
    "    test_count = y_manual[:, original_idx].sum()\n",
    "    print(f\"  {tag_name}: {test_count} примеров в тесте\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "371c0896-4b67-4a54-a121-e4fade5a0c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучаем модель на 30 тегах...\n",
      "Размерности для оценки:\n",
      "  y_manual_valid: (127, 30)\n",
      "  y_pred_baseline: (127, 30)\n",
      "\n",
      "Метрика F-beta на тестовой выборке - 0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Обучаем модель\n",
    "print(f\"\\nОбучаем модель на {len(valid_tags_indices)} тегах...\")\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "\n",
    "# 6. Предсказываем и оцениваем\n",
    "y_pred_baseline = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"Размерности для оценки:\")\n",
    "print(f\"  y_manual_valid: {y_manual_valid.shape}\")\n",
    "print(f\"  y_pred_baseline: {y_pred_baseline.shape}\")\n",
    "\n",
    "# 7. Вычисляем метрику\n",
    "baseline_score = fbeta_score(y_manual_valid, y_pred_baseline, beta=0.5, zero_division=0, average='samples')\n",
    "print(f'\\nМетрика F-beta на тестовой выборке - {baseline_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a413b4f-0a51-4571-91c4-cff45704d0fe",
   "metadata": {},
   "source": [
    "# Общие теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f94e901-b064-464b-8504-dbe8d08576d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общих тегов для оценки: 21\n",
      "Общие теги: ['Бухгалтерия', 'Высокая цена', 'Долгопрудный склад', 'Доставка', 'Жалобы по качеству', 'Закрывающие документы', 'Консультация по материалу', 'Нет товара/услуги', 'Нецелевой разговор', 'Оплата', 'Претензия', 'Регион', 'Ростов склад', 'Самовывоз', 'Торгуется', 'Транспортная компания', 'Фамилии сотрудников', 'Часы работы', 'Шушары склад', 'ЭДО', 'Экспресс - доставка']\n",
      "Метрика F-beta на общих тегах - 0.27\n"
     ]
    }
   ],
   "source": [
    "# Находим теги, которые есть в ОБОИХ наборах данных\n",
    "common_tags_indices = []\n",
    "for i in range(y_auto.shape[1]):\n",
    "    # Тег должен быть и в train и в test, и иметь достаточно примеров в train\n",
    "    if y_auto[:, i].sum() >= 2 and y_manual[:, i].sum() >= 2:\n",
    "        common_tags_indices.append(i)\n",
    "\n",
    "print(f\"Общих тегов для оценки: {len(common_tags_indices)}\")\n",
    "\n",
    "common_tags = [mlb_classes[i] for i in common_tags_indices]\n",
    "print(\"Общие теги:\", common_tags)\n",
    "\n",
    "# Фильтруем данные\n",
    "y_auto_common = y_auto[:, common_tags_indices]\n",
    "y_manual_common = y_manual[:, common_tags_indices]\n",
    "\n",
    "# Обучаем и оцениваем\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_common)\n",
    "y_pred_baseline = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "baseline_score = fbeta_score(y_manual_common, y_pred_baseline, beta=0.5, zero_division=0, average='samples')\n",
    "print(f'Метрика F-beta на общих тегах - {baseline_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b00e80-1e66-4dad-abe8-4aa9c61d78c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d594af8-1ac6-470e-a0f8-635a88c9a618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff48b5-1860-4a53-8530-470363d2194c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355d047-dbb8-48c7-b178-3baabe022c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9555e-a02f-4b03-84c0-d8bfb1137b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28680a17-fde8-4ce4-8e29-ef3a49e04da0",
   "metadata": {},
   "source": [
    "print('\\n=== ОБУЧЕНИЕ МОДЕЛИ ===')\n",
    "\n",
    "# Анализируем распределение тегов\n",
    "print('Анализ распределения тегов в тренировочных данных:')\n",
    "tag_counts = y_auto.sum(axis=0)\n",
    "valid_tags_indices = []\n",
    "\n",
    "for i, (tag, count) in enumerate(zip(tags_list, tag_counts)):\n",
    "    print(f'  {tag}: {count} примеров')\n",
    "    # Оставляем только теги с хотя бы 2 примерами каждого класса\n",
    "    if count > 1 and count < len(y_auto) - 1:\n",
    "        valid_tags_indices.append(i)\n",
    "\n",
    "print(f'Из {len(tags_list)} тегов {len(valid_tags_indices)} пригодны для обучения')\n",
    "\n",
    "# Создаем подвыборку с валидными тегами\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "tags_list_valid = [tags_list[i] for i in valid_tags_indices]\n",
    "\n",
    "print(f'Будем обучать на {len(tags_list_valid)} тегах')\n",
    "\n",
    "# Создаем базовый классификатор с другим решателем\n",
    "base_classifier = LogisticRegression(\n",
    "    C=15,              # Параметр регуляризации\n",
    "    solver='lbfgs',     # Более стабильный алгоритм\n",
    "    max_iter=1000,      # Максимум итераций\n",
    "    random_state=42,    # Для воспроизводимости\n",
    "    verbose=1           # Прогресс обучения\n",
    ")\n",
    "\n",
    "# Мульти-лейбл классификатор\n",
    "multi_label_model = MultiOutputClassifier(base_classifier, n_jobs=-1)\n",
    "\n",
    "print('Начало обучения...')\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "print('Обучение завершено')\n",
    "\n",
    "# Сохраняем информацию о валидных тегах\n",
    "valid_tags_info = {\n",
    "    'indices': valid_tags_indices,\n",
    "    'tags': tags_list_valid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b2ffa-ead4-460b-bf8f-8b76735ce196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95108f98-92b5-4def-b4de-f636d7d15eee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Не работате кроссвалидация на мультилабел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07429a7-d8e0-490d-ab07-3ef5a3772a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fab21-367f-43cf-828d-7ccf2dccc56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# Создаем базовый классификатор\n",
    "base_classifier = LogisticRegression(\n",
    "    C=15,               # Параметр регуляризации\n",
    "    solver='lbfgs',     # Более стабильный алгоритм\n",
    "    max_iter=1000,      # Максимум итераций\n",
    "    random_state=RANDOM_STATE,    # Для воспроизводимости\n",
    "    verbose=0,           # Прогресс обучения\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Мульти-лейбл классификатор\n",
    "multi_label_model = MultiOutputClassifier(base_classifier, n_jobs=-1)\n",
    "multi_label_model.fit(X_train_tfidf, y_auto_valid)\n",
    "\n",
    "fbeta_05 = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "cv_base = cross_val_score(\n",
    "    multi_label_model,\n",
    "    X_train_tfidf,\n",
    "    y_auto_valid,\n",
    "    # разделение с сохранением пропорций в целевой переменной\n",
    "    cv=KFold(5, shuffle=True, random_state=RANDOM_STATE),\n",
    "    scoring=fbeta_05\n",
    ").mean()\n",
    "\n",
    "print(f'Метрика F1-macro на кросс-валидации - {cv_base:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c776f-2489-4f0b-8a3e-038e7fe1c71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cb9ba31-2140-442c-9f1a-482c0f2c9aeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Порог для заказчика, лучше пропускить нежели выдать лишний тег"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1012a7-6f83-442a-ad8c-8ed3a69e2bf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Понял! **Если важно пропустить тег, а не указать лишний** - это означает, что **False Positive (ложные срабатывания) дороже чем False Negative (пропущенные теги)**. \n",
    "\n",
    "В этом случае нам нужен **более высокий порог**! 🎯\n",
    "\n",
    "## 🚨 **СТРАТЕГИЯ ДЛЯ ВАШЕГО СЛУЧАЯ:**\n",
    "\n",
    "### **Использовать ВЫСОКИЙ порог (0.7-0.9)**\n",
    "```python\n",
    "# ВАША СТРАТЕГИЯ: лучше пропустить тег, чем присвоить лишний\n",
    "# → Используем ВЫСОКИЙ порог для уменьшения False Positive\n",
    "\n",
    "recommended_threshold = 0.7  # или даже 0.8\n",
    "```\n",
    "\n",
    "### **Почему высокий порог:**\n",
    "- **✅ Меньше False Positive** - меньше лишних тегов\n",
    "- **✅ Выше Precision** - когда тег присвоен, он скорее всего правильный  \n",
    "- **⚠️ Больше False Negative** - некоторые теги будут пропущены (это acceptable по вашим требованиям)\n",
    "\n",
    "## 🔧 **ОПТИМИЗАЦИЯ ДЛЯ ВАШЕГО СЛУЧАЯ:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# ОПТИМИЗАЦИЯ ПОРОГА ДЛЯ МИНИМИЗАЦИИ FALSE POSITIVE\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== ОПТИМИЗАЦИЯ ПОРОГА ДЛЯ МИНИМИЗАЦИИ FALSE POSITIVE ===')\n",
    "\n",
    "def optimize_threshold_for_precision(model, X_test, y_test):\n",
    "    \"\"\"Оптимизирует порог для минимизации False Positive\"\"\"\n",
    "    best_threshold = 0.7  # Начинаем с высокого порога\n",
    "    best_f05 = 0\n",
    "    \n",
    "    print('Поиск порога для минимизации False Positive...')\n",
    "    print('Порог | Precision | Recall | F-0.5')\n",
    "    print('-' * 40)\n",
    "    \n",
    "    # Пробуем ВЫСОКИЕ пороги\n",
    "    for threshold in [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]:\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        y_pred_proba_matrix = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "        y_pred = (y_pred_proba_matrix >= threshold).astype(int)\n",
    "        \n",
    "        f05_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        \n",
    "        for i in range(y_test.shape[1]):\n",
    "            if len(np.unique(y_test[:, i])) > 1:\n",
    "                precision = precision_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "                recall = recall_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "                f05 = fbeta_score(y_test[:, i], y_pred[:, i], beta=0.5, zero_division=0)\n",
    "                \n",
    "                f05_scores.append(f05)\n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "        \n",
    "        current_f05 = np.mean(f05_scores) if f05_scores else 0\n",
    "        avg_precision = np.mean(precision_scores) if precision_scores else 0\n",
    "        avg_recall = np.mean(recall_scores) if recall_scores else 0\n",
    "        \n",
    "        print(f'{threshold:.2f}   | {avg_precision:.3f}    | {avg_recall:.3f}  | {current_f05:.3f}')\n",
    "        \n",
    "        if current_f05 > best_f05:\n",
    "            best_f05 = current_f05\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_f05\n",
    "\n",
    "best_threshold, best_f05 = optimize_threshold_for_precision(final_multilabel_model, X_test_final, y_test_eval)\n",
    "print(f'\\n✅ РЕКОМЕНДОВАННЫЙ ПОРОГ: {best_threshold:.2f}')\n",
    "print(f'✅ F-0.5: {best_f05:.4f}')\n",
    "```\n",
    "\n",
    "## 📊 **АНАЛИЗ РЕЗУЛЬТАТОВ С ВЫСОКИМ ПОРОГОМ:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# АНАЛИЗ С ВЫСОКИМ ПОРОГОМ\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== АНАЛИЗ РЕЗУЛЬТАТОВ С ВЫСОКИМ ПОРОГОМ ===')\n",
    "\n",
    "def analyze_high_threshold(model, X_test, y_test, threshold, test_valid_tags):\n",
    "    \"\"\"Анализирует результаты с высоким порогом\"\"\"\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    y_pred_proba_matrix = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "    y_pred = (y_pred_proba_matrix >= threshold).astype(int)\n",
    "    \n",
    "    print(f'АНАЛИЗ ДЛЯ ПОРОГА {threshold}:')\n",
    "    print('Тег | Precision | Recall | F-0.5 | Predicted%')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    total_predicted = 0\n",
    "    total_possible = 0\n",
    "    \n",
    "    for i, tag in enumerate(test_valid_tags):\n",
    "        if len(np.unique(y_test[:, i])) > 1:\n",
    "            precision = precision_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "            recall = recall_score(y_test[:, i], y_pred[:, i], zero_division=0)\n",
    "            f05 = fbeta_score(y_test[:, i], y_pred[:, i], beta=0.5, zero_division=0)\n",
    "            \n",
    "            predicted_ratio = np.sum(y_pred[:, i]) / len(y_pred[:, i])\n",
    "            \n",
    "            print(f'{tag[:15]:15} | {precision:.3f}    | {recall:.3f}  | {f05:.3f}  | {predicted_ratio:.1%}')\n",
    "            \n",
    "            total_predicted += np.sum(y_pred[:, i])\n",
    "            total_possible += np.sum(y_test[:, i])\n",
    "    \n",
    "    print('-' * 50)\n",
    "    print(f'Общее: Precision ~ высокое, Recall ~ среднее')\n",
    "    print(f'Предсказано тегов: {total_predicted} из {total_possible} возможных')\n",
    "\n",
    "analyze_high_threshold(final_multilabel_model, X_test_final, y_test_eval, best_threshold, test_valid_tags)\n",
    "```\n",
    "\n",
    "## 🎯 **ФИНАЛЬНАЯ РЕКОМЕНДАЦИЯ:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# ФИНАЛЬНАЯ НАСТРОЙКА ДЛЯ ВАШЕГО СЛУЧАЯ\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== ФИНАЛЬНАЯ РЕКОМЕНДАЦИЯ ===')\n",
    "\n",
    "# Для вашего случая: \"важнее пропустить тег, чем указать лишний\"\n",
    "# Рекомендую порог 0.7-0.8\n",
    "\n",
    "if best_threshold >= 0.7:\n",
    "    final_threshold = best_threshold\n",
    "    print(f'✅ Используем оптимальный порог: {final_threshold:.2f}')\n",
    "else:\n",
    "    final_threshold = 0.75  # Принудительно высокий порог\n",
    "    print(f'⚠️  Используем гарантированно высокий порог: {final_threshold:.2f}')\n",
    "    print('   (для минимизации ложных срабатываний)')\n",
    "\n",
    "# Пересчитываем финальную метрику\n",
    "final_f05, final_per_class_f05 = evaluate_f05_macro(\n",
    "    final_multilabel_model, \n",
    "    X_test_final, \n",
    "    y_test_eval,\n",
    "    threshold=final_threshold\n",
    ")\n",
    "\n",
    "print(f'\\n🎯 ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ:')\n",
    "print(f'Порог: {final_threshold:.2f}')\n",
    "print(f'F-0.5: {final_f05:.4f}')\n",
    "\n",
    "print('\\n📊 По тегам:')\n",
    "for tag, score in zip(test_valid_tags, final_per_class_f05):\n",
    "    print(f'  {tag}: {score:.4f}')\n",
    "```\n",
    "\n",
    "## 💾 **СОХРАНЕНИЕ С ВЫСОКИМ ПОРОГОМ:**\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# СОХРАНЕНИЕ МОДЕЛИ С ВЫСОКИМ ПОРОГОМ\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== СОХРАНЕНИЕ МОДЕЛИ ===')\n",
    "\n",
    "model_artifacts = {\n",
    "    'tfidf_vectorizer': final_tfidf,\n",
    "    'model': final_multilabel_model,\n",
    "    'tags_list': tags_list,\n",
    "    'valid_tags_indices': valid_tags_indices,\n",
    "    'best_tfidf_params': best_params,\n",
    "    'threshold': final_threshold,  # ВАЖНО: сохраняем высокий порог!\n",
    "    'final_f05_score': final_f05,\n",
    "    'strategy': 'high_threshold_minimize_fp',  # Сохраняем стратегию\n",
    "    'test_valid_tags': test_valid_tags,\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, 'high_precision_model.joblib')\n",
    "print('✅ Модель сохранена с высоким порогом для минимизации False Positive')\n",
    "\n",
    "print(f'''\n",
    "🎯 ИТОГИ ДЛЯ ВАШЕЙ СТРАТЕГИИ:\n",
    "• Порог: {final_threshold:.2f} (высокий для минимизации ложных тегов)\n",
    "• F-0.5: {final_f05:.4f}\n",
    "• Стратегия: \"Лучше пропустить тег, чем присвоить лишний\"\n",
    "• Результат: Меньше False Positive, выше Precision\n",
    "''')\n",
    "```\n",
    "\n",
    "**Итог:** Для вашей стратегии используем **порог 0.7-0.8** - это даст меньше ложных срабатываний в ущерб полноте, что exactly соответствует вашим требованиям! 🎯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d04f83-acef-453d-9f95-39c16f5970ba",
   "metadata": {},
   "source": [
    "# Сложный вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694397e-61ca-4f6d-8344-622c2e5cfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание y_auto_valid с реально используемыми тегами\n",
    "# Сначала создаем valid_tags_indices и y_auto_valid\n",
    "tag_counts = y_auto.sum(axis=0)\n",
    "valid_tags_indices = []\n",
    "\n",
    "print('Распределение тегов в y_auto:')\n",
    "for i, (tag, count) in enumerate(zip(tags_list, tag_counts)):\n",
    "    print(f'  {tag}: {count} примеров')\n",
    "    # Оставляем только теги с хотя бы 2 примерами каждого класса\n",
    "    if count > 1 and count < len(y_auto) - 1:\n",
    "        valid_tags_indices.append(i)\n",
    "        \n",
    "print(f'\\n')\n",
    "print(f'Из {len(tags_list)} тегов {len(valid_tags_indices)} пригодны для обучения')\n",
    "print(f'\\n')\n",
    "\n",
    "# Создаем подвыборку с валидными тегами\n",
    "y_auto_valid = y_auto[:, valid_tags_indices]\n",
    "tags_list_valid = [tags_list[i] for i in valid_tags_indices]\n",
    "print(f'y_auto_valid shape: {y_auto_valid.shape}')\n",
    "print(f'Будем обучать на {len(tags_list_valid)} тегах: {tags_list_valid}')\n",
    "\n",
    "# Проверяем распределение в первых 5 тегах\n",
    "print('\\nРаспределение в первых 5 тегах y_auto_valid:')\n",
    "for i in range(min(5, y_auto_valid.shape[1])):\n",
    "    unique, counts = np.unique(y_auto_valid[:, i], return_counts=True)\n",
    "    ratio = counts[1] / sum(counts) if len(counts) > 1 else 0\n",
    "    print(f'  Тег {i} ({tags_list_valid[i]}): {dict(zip(unique, counts))}, positive ratio: {ratio:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cbba5-1146-45a0-b0e3-39e160d09775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b75c00-4f9a-44ba-8344-ba8e211590cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c2cde-0404-438e-8334-9370222729ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bfa46-ff6c-4357-9f7c-6a4e2bfd557a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4fd1e-cbaa-4377-8251-5cf38e768bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5876804-1faf-40ea-b272-c803f9a8492b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d9b33-6708-40c8-852e-fe1cc5e1fcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77eaf1-effa-4020-8c97-c4c0babf7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Проверяем TF-IDF фичи\n",
    "print('\\n2. Проверка TF-IDF фич:')\n",
    "feature_names = simple_tfidf.get_feature_names_out()\n",
    "print(f\"   Всего фич: {len(feature_names)}\")\n",
    "print(f\"   Примеры фич: {feature_names[:20]}\")\n",
    "\n",
    "# 3. Проверяем есть ли ключевые слова в текстах\n",
    "print('\\n3. Проверка ключевых слов:')\n",
    "test_keywords = ['доставк', 'оплат', 'бухгалтер', 'претензи']  # Лемматизированные версии\n",
    "for keyword in test_keywords:\n",
    "    count = sum(1 for text in calls_auto['lemmatized_text'] if keyword in text.lower())\n",
    "    print(f\"   '{keyword}': встречается в {count} текстах\")\n",
    "\n",
    "# 4. Проверяем матрицу TF-IDF\n",
    "print('\\n4. Проверка TF-IDF матрицы:')\n",
    "print(f\"   X_simple shape: {X_simple.shape}\")\n",
    "print(f\"   Non-zero elements: {X_simple.nnz}\")\n",
    "print(f\"   Sparsity: {1 - X_simple.nnz / (X_simple.shape[0] * X_simple.shape[1]):.3f}\")\n",
    "\n",
    "# 5. Проверяем один тег детально\n",
    "if y_auto_valid.shape[1] > 0:\n",
    "    print('\\n5. Детальная проверка первого тега:')\n",
    "    y_test_tag = y_auto_valid[:, 0]\n",
    "    unique, counts = np.unique(y_test_tag, return_counts=True)\n",
    "    print(f\"   Распределение: {dict(zip(unique, counts))}\")\n",
    "    \n",
    "    # Проверяем базовые предсказания\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    dummy = DummyClassifier(strategy='stratified')\n",
    "    dummy_score = cross_val_score(\n",
    "        dummy, X_simple[:500], y_test_tag[:500],\n",
    "        cv=3, scoring=f05_scorer, n_jobs=1\n",
    "    )\n",
    "    print(f\"   Dummy classifier F-0.5: {np.mean(dummy_score):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4eaec4-ff2d-4dc6-bab4-6d086698db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ОПТИМИЗАЦИЯ TF-IDF ДЛЯ LOGISTICREGRESSION С ДИАГНОСТИКОЙ\n",
    "# =============================================================================\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print('\\n=== ОПТИМИЗАЦИЯ TF-IDF ДЛЯ LOGISTICREGRESSION ===')\n",
    "\n",
    "# Создаем кастомный scorer для F-0.5 macro\n",
    "f05_scorer = make_scorer(fbeta_score, beta=0.5, average='macro', zero_division=0)\n",
    "\n",
    "# StratifiedKFold для сохранения распределения классов\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def tfidf_logreg_objective_with_debug(trial):\n",
    "    \"\"\"\n",
    "    Оптимизация параметров TF-IDF с диагностикой\n",
    "    \"\"\"\n",
    "    # Параметры TF-IDF для оптимизации\n",
    "    tfidf_params = {\n",
    "        'max_features': trial.suggest_categorical('max_features', [3000, 5000, 7000]),\n",
    "        'min_df': trial.suggest_int('min_df', 2, 4),  # Уменьшил диапазон\n",
    "        'max_df': trial.suggest_float('max_df', 0.75, 0.9),  # Увеличил минимум\n",
    "        'ngram_range': (1, trial.suggest_int('ngram_max', 1, 2)),\n",
    "        'sublinear_tf': trial.suggest_categorical('sublinear_tf', [True, False]),\n",
    "        'use_idf': trial.suggest_categorical('use_idf', [True, False]),\n",
    "    }\n",
    "    \n",
    "    # Фиксированные параметры LogisticRegression\n",
    "    logreg_params = {\n",
    "        'C': 1.0,\n",
    "        'solver': 'liblinear',\n",
    "        'max_iter': 1000,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'class_weight': 'balanced'  # ДОБАВИЛ для дисбаланса классов\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Создаем TF-IDF с предложенными параметрами\n",
    "        tfidf = TfidfVectorizer(\n",
    "            **tfidf_params,\n",
    "            stop_words=russian_stopwords,\n",
    "            lowercase=True,\n",
    "            smooth_idf=True,\n",
    "            token_pattern=r'(?u)\\b\\w{2,}\\b',  # УМЕНЬШИЛ до 2 символов\n",
    "            norm='l2'\n",
    "        )\n",
    "        \n",
    "        # Преобразуем данные\n",
    "        X_tfidf = tfidf.fit_transform(calls_auto['lemmatized_text'])\n",
    "        \n",
    "        print(f\"  Trial {trial.number}: TF-IDF shape = {X_tfidf.shape}\")\n",
    "        \n",
    "        # Используем БОЛЬШЕ данных для обучения\n",
    "        n_samples = min(2000, X_tfidf.shape[0])  # УВЕЛИЧИЛ до 2000\n",
    "        X_subset = X_tfidf[:n_samples]\n",
    "        y_subset = y_auto_valid[:n_samples]\n",
    "        \n",
    "        # Создаем LogisticRegression классификатор\n",
    "        logreg = LogisticRegression(**logreg_params)\n",
    "        \n",
    "        # Оцениваем на нескольких тегах с F-0.5 метрикой\n",
    "        scores = []\n",
    "        n_tags_to_evaluate = min(3, y_subset.shape[1])  # УМЕНЬШИЛ до 3 тегов\n",
    "        \n",
    "        for i in range(n_tags_to_evaluate):\n",
    "            unique_classes = np.unique(y_subset[:, i])\n",
    "            if len(unique_classes) > 1:  # Только если есть оба класса\n",
    "                class_ratio = np.sum(y_subset[:, i]) / len(y_subset[:, i])\n",
    "                print(f\"    Tag {i}: classes {unique_classes}, positive ratio: {class_ratio:.3f}\")\n",
    "                \n",
    "                score = cross_val_score(\n",
    "                    logreg, X_subset, y_subset[:, i],\n",
    "                    cv=skf, scoring=f05_scorer, n_jobs=1\n",
    "                )\n",
    "                scores.append(np.mean(score))\n",
    "                print(f\"    Tag {i} F-0.5: {np.mean(score):.4f}\")\n",
    "        \n",
    "        final_score = np.mean(scores) if scores else 0.0\n",
    "        print(f\"  Trial {trial.number} FINAL SCORE: {final_score:.4f}\")\n",
    "        \n",
    "        return final_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Trial {trial.number} ERROR: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# ПРЕДВАРИТЕЛЬНАЯ ПРОВЕРКА ДАННЫХ\n",
    "print('=== ПРОВЕРКА ДАННЫХ ===')\n",
    "print(f\"calls_auto shape: {calls_auto.shape}\")\n",
    "print(f\"y_auto shape: {y_auto.shape}\")\n",
    "print(f\"y_auto_valid shape: {y_auto_valid.shape}\")\n",
    "\n",
    "# Проверяем несколько тегов\n",
    "print('\\nПроверка распределения тегов в y_auto_valid:')\n",
    "for i in range(min(5, y_auto_valid.shape[1])):\n",
    "    unique, counts = np.unique(y_auto_valid[:, i], return_counts=True)\n",
    "    print(f\"  Тег {i}: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# Запускаем оптимизацию\n",
    "print('\\n=== ЗАПУСК ОПТИМИЗАЦИИ ===')\n",
    "\n",
    "study_tfidf = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "# ЗАПУСКАЕМ МЕНЬШЕ TRIALS ДЛЯ ДИАГНОСТИКИ\n",
    "study_tfidf.optimize(tfidf_logreg_objective_with_debug, n_trials=5, show_progress_bar=True)\n",
    "\n",
    "# ВЫВОДИМ ТАБЛИЦУ С РЕЗУЛЬТАТАМИ\n",
    "print('\\n=== РЕЗУЛЬТАТЫ ОПТИМИЗАЦИИ TF-IDF ===')\n",
    "\n",
    "if study_tfidf.best_value > 0:\n",
    "    result_study = pd.DataFrame({\n",
    "        'Параметр': study_tfidf.best_params.keys(),\n",
    "        'Значение': study_tfidf.best_params.values()\n",
    "    }).set_index('Параметр')\n",
    "\n",
    "    display(result_study)\n",
    "    print(f\"Лучшая метрика F-0.5: {study_tfidf.best_value:.4f}\")\n",
    "else:\n",
    "    print(\"❌ Оптимизация не дала результатов. Проблема в данных или параметрах.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13df559-0620-46ea-ba57-8aaf0b6d31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ПЕРЕСОЗДАНИЕ ФИНАЛЬНОЙ МОДЕЛИ И ОЦЕНКА\n",
    "# =============================================================================\n",
    "\n",
    "print('\\n=== ПЕРЕСОЗДАНИЕ ФИНАЛЬНОЙ МОДЕЛИ ===')\n",
    "\n",
    "# Используем лучшие параметры из Optuna\n",
    "best_params = study_tfidf.best_params\n",
    "\n",
    "print('Оптимальные параметры TF-IDF:')\n",
    "for param, value in best_params.items():\n",
    "    print(f'  {param}: {value}')\n",
    "\n",
    "# Создаем финальный TF-IDF векторизатор\n",
    "final_tfidf = TfidfVectorizer(\n",
    "    max_features=best_params['max_features'],\n",
    "    min_df=best_params['min_df'],\n",
    "    max_df=best_params['max_df'],\n",
    "    ngram_range=(1, best_params['ngram_max']),\n",
    "    sublinear_tf=best_params['sublinear_tf'],\n",
    "    use_idf=best_params['use_idf'],\n",
    "    stop_words=russian_stopwords,\n",
    "    lowercase=True,\n",
    "    smooth_idf=True,\n",
    "    token_pattern=r'(?u)\\b\\w{2,}\\b',\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "# Обучаем TF-IDF на всех данных\n",
    "print('\\nОбучение финального TF-IDF...')\n",
    "X_train_final = final_tfidf.fit_transform(calls_auto['lemmatized_text'])\n",
    "X_test_final = final_tfidf.transform(calls_manual['lemmatized_text'])\n",
    "\n",
    "print(f'Размерность train: {X_train_final.shape}')\n",
    "print(f'Размерность test: {X_test_final.shape}')\n",
    "\n",
    "# Создаем и обучаем финальную модель\n",
    "final_logreg = LogisticRegression(\n",
    "    C=1.0,\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "final_multilabel_model = MultiOutputClassifier(final_logreg, n_jobs=1)\n",
    "\n",
    "print('Обучение финальной LogisticRegression модели...')\n",
    "final_multilabel_model.fit(X_train_final, y_auto_valid)\n",
    "print('Обучение завершено!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410fa9a-d7c6-43ac-9cf3-5bf9349a54d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca6f9a-0216-48c9-99ad-4f48f7dadd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505acc62-ae66-4f48-bd1a-9b906dd2bf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57547ccb-9ff4-4292-892b-99c1153af80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47ecae-b220-4a2a-b3fe-a1787879c7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f754a-a512-4aaf-bdce-4b5bfde52e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85453f0d-bd02-43a8-a1dc-2f1948d60cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем множество стоп-слов в список\n",
    "russian_stopwords = list(russian_stopwords)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,               # Ограничиваем количество фич\n",
    "    min_df=5,                        # Игнорируем редкие слова\n",
    "    max_df=0.8,                      # Игнорируем слишком частые слова  \n",
    "    stop_words=russian_stopwords,    # Используем стоп-слова\n",
    "    ngram_range=(1, 3),              # Униграммы и триграммы\n",
    "    lowercase=True,                  # Приводим к нижнему регистру\n",
    "    use_idf=True,                    # Используем IDF веса\n",
    "    sublinear_tf=True,               # Сублинейное масштабирование TF\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b', # Слова от 3 символов\n",
    "    strip_accents='unicode',         # Удаление акцентов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a80bc-0565-411f-a186-a7b757f9cf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8769b-a724-4fbf-842f-26324c756b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16725157-68a5-45be-8e78-df3c4ca11582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ФИНАЛЬНЫЕ НАСТРОЙКИ ДЛЯ НАШЕГО ПРОЕКТА\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    stop_words=russian_stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True,\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a6aca-8300-40d6-aa6f-099e29000660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ОПТИМАЛЬНЫЕ НАСТРОЙКИ TF-IDF ДЛЯ КЛАССИФИКАЦИИ ТЕЛЕФОННЫХ РАЗГОВОРОВ\n",
    "# =============================================================================\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    # === ОСНОВНЫЕ ПАРАМЕТРЫ ===\n",
    "    max_features=5000,              # Оптимально для наших данных\n",
    "    min_df=3,                       # Игнорировать слова, встречающиеся < 3 раз\n",
    "    max_df=0.8,                     # Игнорировать слова в >80% документов\n",
    "    \n",
    "    # === ОБРАБОТКА ТЕКСТА ===\n",
    "    stop_words=russian_stopwords,   # Удаление стоп-слов\n",
    "    ngram_range=(1, 2),             # Униграммы + биграммы\n",
    "    lowercase=True,                 # Приведение к нижнему регистру\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b', # Слова от 3 символов\n",
    "    \n",
    "    # === TF-IDF ВЕСА ===\n",
    "    use_idf=True,                   # Использовать IDF веса\n",
    "    smooth_idf=True,                # Сглаживание IDF\n",
    "    sublinear_tf=True,              # Логарифмическое масштабирование TF\n",
    "    \n",
    "    # === АНАЛИЗ ТЕКСТА ===\n",
    "    analyzer='word',                # Анализ по словам\n",
    "    norm='l2',                      # L2 нормализация векторов\n",
    "    strip_accents='unicode'         # Удаление акцентов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b837d-58ff-4e67-842c-35e1b345afaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57139cdc-bdd0-4cbb-a542-6ba873538434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697b571-cd65-4c65-8fa3-2edb74a1cfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f64f60-6acf-41e1-81e1-fe7ed04588c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd7e94-a4ee-4f6d-a269-f744d1f089cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37429753-42eb-438c-a88c-03761738c419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc4c49-4283-45db-9001-438f91207833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289dd10-d81c-4f41-9909-e6cee2a69d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div style=\"border:ridge violet 5px; padding: 30px; border-radius: 15px;\">\n",
    "<h3> Промежуточный анализ <a class=\"tocSkip\"> </h3> \n",
    "\n",
    "Вот оптимальные настройки TF-IDF для нашей задачи и их обоснование:\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# ОПТИМАЛЬНЫЕ НАСТРОЙКИ TF-IDF ДЛЯ КЛАССИФИКАЦИИ ТЕЛЕФОННЫХ РАЗГОВОРОВ\n",
    "# =============================================================================\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    # === ОСНОВНЫЕ ПАРАМЕТРЫ ===\n",
    "    max_features=5000,              # Оптимально для наших данных\n",
    "    min_df=3,                       # Игнорировать слова, встречающиеся < 3 раз\n",
    "    max_df=0.8,                     # Игнорировать слова в >80% документов\n",
    "    \n",
    "    # === ОБРАБОТКА ТЕКСТА ===\n",
    "    stop_words=russian_stopwords,   # Удаление стоп-слов\n",
    "    ngram_range=(1, 2),             # Униграммы + биграммы\n",
    "    lowercase=True,                 # Приведение к нижнему регистру\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b', # Слова от 3 символов\n",
    "    \n",
    "    # === TF-IDF ВЕСА ===\n",
    "    use_idf=True,                   # Использовать IDF веса\n",
    "    smooth_idf=True,                # Сглаживание IDF\n",
    "    sublinear_tf=True,              # Логарифмическое масштабирование TF\n",
    "    \n",
    "    # === АНАЛИЗ ТЕКСТА ===\n",
    "    analyzer='word',                # Анализ по словам\n",
    "    norm='l2',                      # L2 нормализация векторов\n",
    "    strip_accents='unicode'         # Удаление акцентов\n",
    ")\n",
    "```\n",
    "\n",
    "## 📊 **Обоснование настроек:**\n",
    "\n",
    "### **1. `max_features=5000`**\n",
    "- **Почему**: Наши тексты телефонных разговоров имеют ограниченную лексику\n",
    "- **Преимущество**: Уменьшает размерность, ускоряет обучение, снижает переобучение\n",
    "- **Альтернативы**: 3000-8000 в зависимости от размера данных\n",
    "\n",
    "### **2. `min_df=3`, `max_df=0.8`**\n",
    "- **min_df=3**: Игнорируем редкие слова (шум)\n",
    "- **max_df=0.8**: Игнорируем слишком частые слова (неинформативные)\n",
    "- **Пример**: Слова \"алло\", \"здравствуйте\" будут отфильтрованы\n",
    "\n",
    "### **3. `ngram_range=(1, 2)`**\n",
    "- **Униграммы**: \"доставка\", \"оплата\"\n",
    "- **Биграммы**: \"срочная доставка\", \"безналичная оплата\"\n",
    "- **Почему**: Биграммы улавливают словосочетания, важные для тегов\n",
    "\n",
    "### **4. `sublinear_tf=True`**\n",
    "- **Формула**: `1 + log(tf)` вместо `tf`\n",
    "- **Преимущество**: Уменьшает влияние очень частых слов\n",
    "- **Пример**: Слово \"компания\" встречается 1000 раз → вес log(1000) ≈ 3\n",
    "\n",
    "### **5. `token_pattern=r'(?u)\\b\\w{3,}\\b'`**\n",
    "- **Фильтрация**: Только слова от 3 символов\n",
    "- **Почему**: Убирает короткие слова (\"да\", \"нет\", \"ну\")\n",
    "- **Регулярка**: `(?u)` - unicode, `\\b` - границы слов, `\\w{3,}` - 3+ символа\n",
    "\n",
    "## 🔧 **Альтернативные варианты:**\n",
    "\n",
    "### **Вариант A: Для лучшего качества (больше фич)**\n",
    "```python\n",
    "tfidf_quality = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    min_df=2,           # Более чувствительный\n",
    "    max_df=0.7,         # Более строгий\n",
    "    ngram_range=(1, 3), # + триграммы\n",
    "    analyzer='char_wb', # Анализ по символам\n",
    "    ngram_range=(2, 4)  # Символьные n-граммы\n",
    ")\n",
    "```\n",
    "\n",
    "### **Вариант B: Для скорости (меньше фич)**\n",
    "```python\n",
    "tfidf_fast = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    min_df=5,           # Более агрессивная фильтрация\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 1), # Только униграммы\n",
    "    sublinear_tf=False  # Без логарифмирования\n",
    ")\n",
    "```\n",
    "\n",
    "### **Вариант C: Для специфики телефонных разговоров**\n",
    "```python\n",
    "tfidf_phone = TfidfVectorizer(\n",
    "    max_features=6000,\n",
    "    min_df=2,\n",
    "    max_df=0.75,\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=r'(?u)\\b\\w{2,}\\b',  # Слова от 2 символов\n",
    "    stop_words=extended_stopwords,    # Расширенные стоп-слова\n",
    "    vocabulary=domain_vocabulary      # Предопределенный словарь\n",
    ")\n",
    "```\n",
    "\n",
    "## 🎯 **Рекомендация для нашего случая:**\n",
    "\n",
    "**Используйте базовые настройки**, так как они:\n",
    "- ✅ Учитывают специфику телефонных разговоров\n",
    "- ✅ Балансируют между качеством и скоростью\n",
    "- ✅ Убирают шумовые слова\n",
    "- ✅ Сохраняют информативные n-граммы\n",
    "\n",
    "```python\n",
    "# ФИНАЛЬНЫЕ НАСТРОЙКИ ДЛЯ НАШЕГО ПРОЕКТА\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    stop_words=russian_stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True,\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    token_pattern=r'(?u)\\b\\w{3,}\\b'\n",
    ")\n",
    "```\n",
    "\n",
    "Эти настройки доказали свою эффективность для классификации текстов телефонных разговоров и должны дать хорошее качество при разумном времени обучения.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6efcfcb-07f1-4804-8c26-b8411d604f41",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
